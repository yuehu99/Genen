{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90025b3e-58df-46ee-b463-2df4c05fdd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3667212/1957606864.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import obonet\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c04296-1155-49af-b45f-786c27e33bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
      "0            FES  0.339602 -0.030744 -0.901381  0.100888  0.886443  0.383596   \n",
      "1         HADHA  -0.131799 -0.025745 -0.677301 -0.053545  0.971046  0.180315   \n",
      "2         SLC7A7  0.385693 -0.070692 -0.847796 -0.022054  0.959772  0.085487   \n",
      "3           LCK   0.650428  0.014479 -0.866163  0.053508  0.951529  0.269402   \n",
      "4          HSPA2  0.322262  0.017484 -0.849302  0.046401  0.920429  0.463832   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "69872    MIR29B2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "69873     PLXNA2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "69874     CELA2A  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "69875     CELA2B  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "69876  SCARNA21B  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "       feature7  feature8  feature9  ...  feature759  feature760  feature761  \\\n",
      "0     -0.192082 -0.032063 -0.154869  ...   -0.549204   -0.856123    0.714672   \n",
      "1     -0.028189 -0.077389 -0.095152  ...    0.927885   -0.817812    0.809631   \n",
      "2      0.076455 -0.003006 -0.032268  ...    0.941094   -0.912443    0.789828   \n",
      "3     -0.214788  0.045179 -0.506429  ...   -0.576739   -0.969558    0.916549   \n",
      "4     -0.050414 -0.033398  0.387791  ...    0.387301   -0.860696    0.678607   \n",
      "...         ...       ...       ...  ...         ...         ...         ...   \n",
      "69872  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
      "69873  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
      "69874  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
      "69875  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
      "69876  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
      "\n",
      "       feature762  feature763  feature764  feature765  feature766  feature767  \\\n",
      "0       -0.046649   -0.894424   -0.001815    0.739485    0.015581   -0.023863   \n",
      "1       -0.005827   -0.848839    0.024516    0.526404   -0.039926   -0.102787   \n",
      "2        0.046979   -0.715636    0.085842    0.150494    0.025392   -0.066035   \n",
      "3       -0.080332   -0.927649   -0.047398    0.741663   -0.000096   -0.096318   \n",
      "4       -0.060695   -0.945793    0.040472    0.831079   -0.001711   -0.079842   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "69872    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "69873    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "69874    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "69875    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "69876    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "\n",
      "       feature768  \n",
      "0       -0.022002  \n",
      "1       -0.026980  \n",
      "2       -0.028283  \n",
      "3       -0.056501  \n",
      "4       -0.011189  \n",
      "...           ...  \n",
      "69872    0.000000  \n",
      "69873    0.000000  \n",
      "69874    0.000000  \n",
      "69875    0.000000  \n",
      "69876    0.000000  \n",
      "\n",
      "[69877 rows x 769 columns]\n",
      "        Unnamed: 0      Source      Target\n",
      "0                0  GO:0000001  GO:0048308\n",
      "1                1  GO:0000001  GO:0048311\n",
      "2                2  GO:0000002  GO:0007005\n",
      "3                3  GO:0000003  GO:0008150\n",
      "4                4  GO:0000006  GO:0005385\n",
      "...            ...         ...         ...\n",
      "477023      456584  GO:0032880     PLEKHM2\n",
      "477024      456585  GO:0010008     PLEKHM2\n",
      "477025      456586  GO:0019894     PLEKHM2\n",
      "477026      456587  GO:0032418     PLEKHM2\n",
      "477027      456588  GO:0042267     PLEKHM2\n",
      "\n",
      "[477028 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_df = pd.read_csv(\"GNN/go_protein_features.csv\")\n",
    "edges_df = pd.read_csv(\"GNN/GO_gene_edges.csv\")\n",
    "print(features_df)\n",
    "print(edges_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3deaa85-accf-4978-8208-555becf36350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature759</th>\n",
       "      <th>feature760</th>\n",
       "      <th>feature761</th>\n",
       "      <th>feature762</th>\n",
       "      <th>feature763</th>\n",
       "      <th>feature764</th>\n",
       "      <th>feature765</th>\n",
       "      <th>feature766</th>\n",
       "      <th>feature767</th>\n",
       "      <th>feature768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FES</td>\n",
       "      <td>0.339602</td>\n",
       "      <td>-0.030744</td>\n",
       "      <td>-0.901381</td>\n",
       "      <td>0.100888</td>\n",
       "      <td>0.886443</td>\n",
       "      <td>0.383596</td>\n",
       "      <td>-0.192082</td>\n",
       "      <td>-0.032063</td>\n",
       "      <td>-0.154869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549204</td>\n",
       "      <td>-0.856123</td>\n",
       "      <td>0.714672</td>\n",
       "      <td>-0.046649</td>\n",
       "      <td>-0.894424</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.739485</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.022002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HADHA</td>\n",
       "      <td>-0.131799</td>\n",
       "      <td>-0.025745</td>\n",
       "      <td>-0.677301</td>\n",
       "      <td>-0.053545</td>\n",
       "      <td>0.971046</td>\n",
       "      <td>0.180315</td>\n",
       "      <td>-0.028189</td>\n",
       "      <td>-0.077389</td>\n",
       "      <td>-0.095152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927885</td>\n",
       "      <td>-0.817812</td>\n",
       "      <td>0.809631</td>\n",
       "      <td>-0.005827</td>\n",
       "      <td>-0.848839</td>\n",
       "      <td>0.024516</td>\n",
       "      <td>0.526404</td>\n",
       "      <td>-0.039926</td>\n",
       "      <td>-0.102787</td>\n",
       "      <td>-0.026980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLC7A7</td>\n",
       "      <td>0.385693</td>\n",
       "      <td>-0.070692</td>\n",
       "      <td>-0.847796</td>\n",
       "      <td>-0.022054</td>\n",
       "      <td>0.959772</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.076455</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.032268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>-0.912443</td>\n",
       "      <td>0.789828</td>\n",
       "      <td>0.046979</td>\n",
       "      <td>-0.715636</td>\n",
       "      <td>0.085842</td>\n",
       "      <td>0.150494</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>-0.066035</td>\n",
       "      <td>-0.028283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LCK</td>\n",
       "      <td>0.650428</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>-0.866163</td>\n",
       "      <td>0.053508</td>\n",
       "      <td>0.951529</td>\n",
       "      <td>0.269402</td>\n",
       "      <td>-0.214788</td>\n",
       "      <td>0.045179</td>\n",
       "      <td>-0.506429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576739</td>\n",
       "      <td>-0.969558</td>\n",
       "      <td>0.916549</td>\n",
       "      <td>-0.080332</td>\n",
       "      <td>-0.927649</td>\n",
       "      <td>-0.047398</td>\n",
       "      <td>0.741663</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.096318</td>\n",
       "      <td>-0.056501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSPA2</td>\n",
       "      <td>0.322262</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>-0.849302</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.920429</td>\n",
       "      <td>0.463832</td>\n",
       "      <td>-0.050414</td>\n",
       "      <td>-0.033398</td>\n",
       "      <td>0.387791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387301</td>\n",
       "      <td>-0.860696</td>\n",
       "      <td>0.678607</td>\n",
       "      <td>-0.060695</td>\n",
       "      <td>-0.945793</td>\n",
       "      <td>0.040472</td>\n",
       "      <td>0.831079</td>\n",
       "      <td>-0.001711</td>\n",
       "      <td>-0.079842</td>\n",
       "      <td>-0.011189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69872</th>\n",
       "      <td>MIR29B2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69873</th>\n",
       "      <td>PLXNA2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69874</th>\n",
       "      <td>CELA2A</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69875</th>\n",
       "      <td>CELA2B</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69876</th>\n",
       "      <td>SCARNA21B</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69877 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0            FES  0.339602 -0.030744 -0.901381  0.100888  0.886443  0.383596   \n",
       "1         HADHA  -0.131799 -0.025745 -0.677301 -0.053545  0.971046  0.180315   \n",
       "2         SLC7A7  0.385693 -0.070692 -0.847796 -0.022054  0.959772  0.085487   \n",
       "3           LCK   0.650428  0.014479 -0.866163  0.053508  0.951529  0.269402   \n",
       "4          HSPA2  0.322262  0.017484 -0.849302  0.046401  0.920429  0.463832   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "69872    MIR29B2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "69873     PLXNA2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "69874     CELA2A  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "69875     CELA2B  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "69876  SCARNA21B  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       feature7  feature8  feature9  ...  feature759  feature760  feature761  \\\n",
       "0     -0.192082 -0.032063 -0.154869  ...   -0.549204   -0.856123    0.714672   \n",
       "1     -0.028189 -0.077389 -0.095152  ...    0.927885   -0.817812    0.809631   \n",
       "2      0.076455 -0.003006 -0.032268  ...    0.941094   -0.912443    0.789828   \n",
       "3     -0.214788  0.045179 -0.506429  ...   -0.576739   -0.969558    0.916549   \n",
       "4     -0.050414 -0.033398  0.387791  ...    0.387301   -0.860696    0.678607   \n",
       "...         ...       ...       ...  ...         ...         ...         ...   \n",
       "69872  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "69873  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "69874  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "69875  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "69876  0.000000  0.000000  0.000000  ...    0.000000    0.000000    0.000000   \n",
       "\n",
       "       feature762  feature763  feature764  feature765  feature766  feature767  \\\n",
       "0       -0.046649   -0.894424   -0.001815    0.739485    0.015581   -0.023863   \n",
       "1       -0.005827   -0.848839    0.024516    0.526404   -0.039926   -0.102787   \n",
       "2        0.046979   -0.715636    0.085842    0.150494    0.025392   -0.066035   \n",
       "3       -0.080332   -0.927649   -0.047398    0.741663   -0.000096   -0.096318   \n",
       "4       -0.060695   -0.945793    0.040472    0.831079   -0.001711   -0.079842   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "69872    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "69873    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "69874    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "69875    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "69876    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "       feature768  \n",
       "0       -0.022002  \n",
       "1       -0.026980  \n",
       "2       -0.028283  \n",
       "3       -0.056501  \n",
       "4       -0.011189  \n",
       "...           ...  \n",
       "69872    0.000000  \n",
       "69873    0.000000  \n",
       "69874    0.000000  \n",
       "69875    0.000000  \n",
       "69876    0.000000  \n",
       "\n",
       "[69877 rows x 769 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.rename(columns={'Unnamed: 0': 'name'}, inplace=True)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b324f0-db9b-4b9b-b1f1-1b228e2d8ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>GO:0048308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>GO:0048311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>GO:0007005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000003</td>\n",
       "      <td>GO:0008150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>GO:0005385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477023</th>\n",
       "      <td>GO:0032880</td>\n",
       "      <td>PLEKHM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477024</th>\n",
       "      <td>GO:0010008</td>\n",
       "      <td>PLEKHM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477025</th>\n",
       "      <td>GO:0019894</td>\n",
       "      <td>PLEKHM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477026</th>\n",
       "      <td>GO:0032418</td>\n",
       "      <td>PLEKHM2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477027</th>\n",
       "      <td>GO:0042267</td>\n",
       "      <td>PLEKHM2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477028 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source      Target\n",
       "0       GO:0000001  GO:0048308\n",
       "1       GO:0000001  GO:0048311\n",
       "2       GO:0000002  GO:0007005\n",
       "3       GO:0000003  GO:0008150\n",
       "4       GO:0000006  GO:0005385\n",
       "...            ...         ...\n",
       "477023  GO:0032880     PLEKHM2\n",
       "477024  GO:0010008     PLEKHM2\n",
       "477025  GO:0019894     PLEKHM2\n",
       "477026  GO:0032418     PLEKHM2\n",
       "477027  GO:0042267     PLEKHM2\n",
       "\n",
       "[477028 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df = edges_df.drop(edges_df.columns[0], axis=1)\n",
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6cd6378-ba30-4615-ba23-6a09c862aa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 从特征数据集获取节点\n",
    "nodes_in_features = set(features_df['name'])\n",
    "\n",
    "# 找出共同的节点\n",
    "#common_nodes = nodes_in_edges.intersection(nodes_in_features)\n",
    "\n",
    "# 过滤边数据集，保留只包含共同节点的边\n",
    "filtered_edges_df = edges_df[\n",
    "    edges_df['Source'].isin(nodes_in_features) & edges_df['Target'].isin(nodes_in_features)\n",
    "]\n",
    "# 过滤特征数据集，保留共同节点的特征\n",
    "#filtered_features_df = features_df[features_df['name'].isin(common_nodes)].reset_index(drop=True)\n",
    "features = features_df.iloc[:, 1:].values\n",
    "features_tensor = torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d56d2782-2632-41bb-a3ad-fc705d149a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14450, 14450, 14451,  ..., 27025, 30072, 34671],\n",
       "        [39999, 40002, 19879,  ...,  4926,  4926,  4926]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_id_to_index = {node_id: i for i, node_id in enumerate(features_df['name'])}\n",
    "# 确保edge_index是按照这个新的索引顺序排列的\n",
    "source_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['Source']]\n",
    "target_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['Target']]\n",
    "edge_index = torch.tensor([source_indices, target_indices], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63fa05d3-5f80-493d-a96e-d5e52be6a786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>Label</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Count_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERAP2</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Low Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDNF</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>RPS9</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>FBN3</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>BDH2</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       protein Solubility  Label  Word_Count Count_Category\n",
       "0        ERAP2   Membrane      0         117     High Count\n",
       "1     ADAMTSL5    Soluble      1          28      Low Count\n",
       "2      TBC1D30   Membrane      0          55     High Count\n",
       "3       KCNK18   Membrane      0         184     High Count\n",
       "4         NDNF    Soluble      1         129     High Count\n",
       "...        ...        ...    ...         ...            ...\n",
       "1374   TRABD2B   Membrane      0          96     High Count\n",
       "1375      RPS9    Soluble      1         205     High Count\n",
       "1376  SLC22A16   Membrane      0          93     High Count\n",
       "1377      FBN3    Soluble      1          90     High Count\n",
       "1378      BDH2    Soluble      1         102     High Count\n",
       "\n",
       "[1379 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('GNN/solubility.csv')\n",
    "labels_df.rename(columns={'Gene name': 'protein'}, inplace=True)\n",
    "labels_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f8e89c0-534a-46c4-910d-e5709e897da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "1379\n",
      "69877\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_df))\n",
    "nodes_in_labels = set(labels_df['protein'])\n",
    "nodes_in_filter_features = set(features_df['name'])\n",
    "common_nodes_labels = nodes_in_labels.intersection(nodes_in_filter_features)\n",
    "\n",
    "# 过滤\n",
    "filtered_labels_df = labels_df[labels_df['protein'].isin(common_nodes_labels)].reset_index(drop=True)\n",
    "print(len(filtered_labels_df))\n",
    "print(len(features_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86426f08-5b1b-4b0f-8f40-7c0f973cbadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>Label</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Count_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERAP2</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Low Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDNF</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>RPS9</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>FBN3</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>BDH2</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       protein Solubility  Label  Word_Count Count_Category\n",
       "0        ERAP2   Membrane      0         117     High Count\n",
       "1     ADAMTSL5    Soluble      1          28      Low Count\n",
       "2      TBC1D30   Membrane      0          55     High Count\n",
       "3       KCNK18   Membrane      0         184     High Count\n",
       "4         NDNF    Soluble      1         129     High Count\n",
       "...        ...        ...    ...         ...            ...\n",
       "1374   TRABD2B   Membrane      0          96     High Count\n",
       "1375      RPS9    Soluble      1         205     High Count\n",
       "1376  SLC22A16   Membrane      0          93     High Count\n",
       "1377      FBN3    Soluble      1          90     High Count\n",
       "1378      BDH2    Soluble      1         102     High Count\n",
       "\n",
       "[1379 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a574940-1741-4110-b15f-d6c03d85744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 81, 93, 94, 100, 116, 129, 142, 148, 149, 157, 167, 170, 202, 228, 236, 241, 243, 255, 258, 276, 281, 287, 294, 305, 319, 321, 334, 340, 369, 373, 375, 383, 384, 399, 402, 418, 447, 455, 474, 483, 484, 490, 498, 511, 518, 526, 558, 569, 585, 586, 587, 593, 594, 595, 596, 599, 615, 641, 653, 654, 664, 682, 736, 754, 762, 764, 773, 777, 781, 833, 852, 894, 895, 899, 915, 917, 938, 944, 957, 982, 983, 997, 1003, 1019, 1040, 1047, 1053, 1062, 1064, 1065, 1067, 1074, 1075, 1078, 1079, 1105, 1108, 1115, 1116, 1120, 1124, 1131, 1136, 1137, 1143, 1157, 1170, 1173, 1183, 1195, 1196, 1197, 1215, 1235, 1236, 1237, 1243, 1256, 1261, 1262, 1273, 1274, 1277, 1311, 1315, 1327, 1333, 1347, 1363, 1371, 1377, 1378, 1383, 1392, 1397, 1426, 1427, 1431, 1435, 1444, 1445, 1469, 1470, 1475, 1484, 1489, 1492, 1493, 1521, 1527, 1540, 1548, 1559, 1575, 1593, 1606, 1609, 1614, 1617, 1619, 1637, 1638, 1645, 1674, 1681, 1710, 1720, 1733, 1736, 1737, 1759, 1776, 1795, 1807, 1823, 1833, 1834, 1844, 1848, 1849, 1852, 1854, 1882, 1893, 1895, 1898, 1914, 1917, 1923, 1927, 1960, 1970, 1972, 1978, 1986, 1995, 2015, 2016, 2022, 2031, 2046, 2048, 2071, 2096, 2097, 2099, 2101, 2104, 2109, 2112, 2115, 2117, 2119, 2140, 2151, 2154, 2166, 2188, 2196, 2209, 2214, 2227, 2231, 2238, 2250, 2256, 2265, 2273, 2274, 2277, 2281, 2283, 2284, 2286, 2292, 2293, 2302, 2308, 2316, 2326, 2337, 2353, 2354, 2358, 2362, 2364, 2365, 2370, 2372, 2400, 2417, 2419, 2421, 2422, 2424, 2427, 2455, 2465, 2476, 2481, 2489, 2496, 2505, 2532, 2533, 2535, 2540, 2551, 2556, 2589, 2620, 2625, 2630, 2634, 2660, 2672, 2676, 2686, 2701, 2705, 2708, 2716, 2730, 2738, 2767, 2770, 2785, 2788, 2802, 2804, 2819, 2823, 2827, 2836, 2842, 2862, 2871, 2879, 2888, 2896, 2903, 2907, 2915, 2927, 2928, 2929, 2937, 2950, 2957, 2958, 2960, 2982, 2986, 2995, 3000, 3013, 3014, 3021, 3024, 3027, 3037, 3043, 3044, 3054, 3057, 3064, 3084, 3092, 3099, 3117, 3123, 3147, 3150, 3159, 3180, 3186, 3217, 3240, 3244, 3255, 3268, 3272, 3285, 3291, 3305, 3319, 3325, 3326, 3327, 3330, 3353, 3356, 3382, 3389, 3393, 3408, 3410, 3417, 3433, 3454, 3456, 3465, 3486, 3502, 3511, 3519, 3530, 3535, 3536, 3538, 3543, 3584, 3615, 3619, 3620, 3630, 3647, 3663, 3680, 3684, 3692, 3706, 3707, 3715, 3727, 3747, 3751, 3752, 3754, 3774, 3779, 3781, 3783, 3785, 3786, 3792, 3797, 3802, 3810, 3829, 3833, 3839, 3850, 3882, 3884, 3886, 3902, 3917, 3921, 3923, 3929, 3943, 3949, 3959, 3960, 3968, 3969, 3977, 3985, 3990, 3991, 3992, 4019, 4025, 4034, 4040, 4048, 4049, 4071, 4102, 4120, 4133, 4159, 4165, 4166, 4169, 4178, 4184, 4185, 4197, 4209, 4225, 4232, 4239, 4249, 4251, 4258, 4288, 4323, 4328, 4332, 4333, 4343, 4351, 4360, 4361, 4365, 4375, 4376, 4387, 4417, 4431, 4433, 4438, 4439, 4440, 4464, 4465, 4484, 4485, 4495, 4500, 4507, 4513, 4520, 4524, 4526, 4539, 4545, 4558, 4560, 4565, 4572, 4607, 4616, 4630, 4637, 4653, 4656, 4668, 4676, 4711, 4712, 4716, 4721, 4751, 4760, 4776, 4780, 4783, 4792, 4795, 4796, 4800, 4804, 4806, 4815, 4833, 4836, 4840, 4853, 4882, 4888, 4897, 4913, 4915, 4926, 4930, 4935, 4961, 4963, 4995, 4999, 5006, 5013, 5020, 5041, 5061, 5072, 5077, 5079, 5083, 5085, 5124, 5139, 5144, 5146, 5151, 5154, 5167, 5170, 5173, 5178, 5192, 5209, 5216, 5218, 5226, 5228, 5233, 5242, 5243, 5253, 5264, 5271, 5278, 5280, 5298, 5306, 5312, 5327, 5351, 5379, 5383, 5396, 5399, 5405, 5410, 5418, 5437, 5486, 5488, 5506, 5510, 5512, 5513, 5522, 5555, 5556, 5566, 5569, 5570, 5575, 5582, 5586, 5589, 5593, 5628, 5634, 5635, 5644, 5670, 5674, 5687, 5693, 5702, 5703, 5710, 5713, 5721, 5736, 5738, 5784, 5785, 5787, 5792, 5793, 5820, 5823, 5866, 5884, 5890, 5898, 5899, 5900, 5902, 5913, 5943, 5954, 5958, 5963, 5985, 5991, 5992, 6006, 6011, 6038, 6043, 6057, 6058, 6064, 6066, 6078, 6081, 6094, 6099, 6101, 6112, 6119, 6120, 6127, 6128, 6131, 6134, 6136, 6168, 6177, 6179, 6196, 6203, 6211, 6223, 6226, 6227, 6239, 6246, 6278, 6301, 6302, 6314, 6319, 6328, 6343, 6377, 6389, 6416, 6426, 6427, 6428, 6436, 6438, 6448, 6460, 6494, 6514, 6516, 6517, 6518, 6527, 6528, 6549, 6556, 6559, 6562, 6567, 6569, 6579, 6583, 6593, 6595, 6606, 6607, 6612, 6623, 6628, 6630, 6639, 6667, 6679, 6681, 6699, 6702, 6703, 6714, 6717, 6728, 6744, 6772, 6774, 6782, 6785, 6792, 6804, 6815, 6819, 6823, 6832, 6844, 6850, 6859, 6865, 6871, 6884, 6885, 6886, 6943, 6947, 6963, 6995, 7000, 7017, 7018, 7019, 7026, 7040, 7047, 7049, 7065, 7067, 7073, 7074, 7081, 7083, 7089, 7093, 7108, 7116, 7125, 7130, 7139, 7151, 7152, 7153, 7157, 7170, 7185, 7189, 7192, 7201, 7202, 7203, 7221, 7252, 7266, 7278, 7280, 7281, 7286, 7296, 7300, 7312, 7313, 7341, 7349, 7357, 7365, 7375, 7377, 7387, 7389, 7390, 7412, 7415, 7420, 7427, 7433, 7440, 7449, 7456, 7465, 7469, 7481, 7510, 7520, 7527, 7528, 7549, 7561, 7563, 7564, 7573, 7590, 7591, 7599, 7609, 7610, 7631, 7634, 7640, 7645, 7653, 7654, 7665, 7688, 7692, 7705, 7715, 7721, 7755, 7760, 7769, 7782, 7783, 7793, 7839, 7865, 7889, 7891, 7892, 7921, 7930, 7956, 7958, 8012, 8013, 8031, 8041, 8046, 8060, 8066, 8073, 8075, 8077, 8078, 8124, 8139, 8156, 8175, 8189, 8196, 8204, 8212, 8215, 8225, 8226, 8228, 8229, 8231, 8234, 8243, 8250, 8262, 8266, 8272, 8285, 8290, 8303, 8305, 8323, 8327, 8329, 8339, 8343, 8348, 8349, 8350, 8351, 8356, 8357, 8360, 8366, 8383, 8386, 8389, 8405, 8413, 8419, 8441, 8447, 8451, 8454, 8467, 8480, 8491, 8492, 8497, 8517, 8519, 8535, 8554, 8557, 8560, 8567, 8568, 8576, 8592, 8595, 8600, 8608, 8631, 8632, 8633, 8641, 8645, 8647, 8653, 8672, 8683, 8691, 8716, 8720, 8727, 8733, 8741, 8746, 8748, 8749, 8786, 8808, 8814, 8815, 8818, 8820, 8826, 8828, 8865, 8903, 8927, 8931, 8942, 8946, 8991, 8998, 9013, 9026, 9027, 9056, 9066, 9085, 9097, 9098, 9115, 9126, 9134, 9135, 9144, 9148, 9165, 9189, 9190, 9225, 9231, 9246, 9263, 9293, 9301, 9302, 9323, 9325, 9364, 9385, 9410, 9416, 9423, 9431, 9435, 9437, 9457, 9500, 9512, 9514, 9517, 9535, 9547, 9552, 9561, 9573, 9589, 9607, 9627, 9638, 9639, 9659, 9682, 9708, 9757, 9772, 9776, 9784, 9800, 9809, 9822, 9823, 9828, 9836, 9852, 9853, 9862, 9875, 9885, 9900, 9908, 9910, 9926, 9937, 9978, 10000, 10010, 10023, 10031, 10038, 10045, 10046, 10053, 10060, 10063, 10075, 10090, 10094, 10119, 10125, 10138, 10146, 10147, 10151, 10158, 10159, 10168, 10172, 10183, 10201, 10217, 10246, 10298, 10300, 10309, 10321, 10323, 10325, 10327, 10364, 10372, 10379, 10390, 10409, 10410, 10411, 10418, 10424, 10432, 10435, 10436, 10443, 10452, 10459, 10479, 10483, 10485, 10500, 10502, 10527, 10534, 10536, 10542, 10552, 10561, 10580, 10581, 10607, 10619, 10622, 10623, 10629, 10655, 10666, 10685, 10686, 10695, 10697, 10699, 10700, 10701, 10705, 10708, 10730, 10732, 10751, 10754, 10764, 10765, 10776, 10779, 10789, 10794, 10825, 10828, 10862, 10877, 10887, 10890, 10905, 10917, 10926, 10934, 10951, 10988, 11000, 11002, 11022, 11028, 11033, 11035, 11040, 11050, 11089, 11108, 11109, 11125, 11140, 11142, 11150, 11164, 11175, 11178, 11184, 11187, 11192, 11210, 11222, 11247, 11248, 11273, 11277, 11278, 11286, 11289, 11296, 11307, 11321, 11324, 11340, 11343, 11345, 11362, 11406, 11407, 11410, 11418, 11428, 11458, 11482, 11492, 11497, 11523, 11533, 11538, 11542, 11548, 11549, 11562, 11572, 11583, 11601, 11609, 11634, 11638, 11655, 11657, 11658, 11676, 11688, 11707, 11711, 11734, 11746, 11749, 11752, 11758, 11774, 11803, 11805, 11810, 11820, 11844, 11887, 11928, 11938, 11951, 11958, 11967, 11984, 11987, 12071, 12080, 12102, 12103, 12107, 12111, 12116, 12124, 12130, 12142, 12151, 12154, 12169, 12174, 12193, 12194, 12199, 12205, 12262, 12271, 12272, 12284, 12289, 12296, 12302, 12304, 12323, 12345, 12348, 12358, 12373, 12386, 12429, 12432, 12457, 12470, 12487, 12488, 12511, 12517, 12578, 12579, 12587, 12593, 12666, 12667, 12684, 12705, 12706, 12760, 12776, 12784, 12805, 12819, 12821, 12848, 12864, 12873, 12889, 12918, 12954, 12955, 12956, 12958, 12959, 12974, 13001, 13003, 13017, 13022, 13042, 13045, 13049, 13078, 13083, 13084, 13088, 13090, 13120, 13130, 13138, 13164, 13165, 13181, 13186, 13192, 13206, 13214, 13243, 13251, 13266, 13292, 13295, 13305, 13314, 13321, 13334, 13394, 13409, 13422, 13443, 13447, 13469, 13502, 13512, 13536, 13559, 13566, 13567, 13571, 13580, 13582, 13586, 13594, 13657, 13662, 13666, 13672, 13673, 13685, 13724, 13727, 13741, 13760, 13779, 13826, 13831, 13838, 13847, 13855, 13858, 13862, 13871, 13872, 13874, 13882, 13892, 13898, 13901, 13906, 13924, 13931, 13936, 13943, 13951, 13965, 13978, 13984, 14012, 14015, 14024, 14036, 14052, 14090, 14117, 14146, 14151, 14162, 14214, 14234, 14240, 14241, 14263, 14268, 14279, 14281, 14288, 14293, 14315, 14317, 14318, 14324, 14325, 14398, 14407, 14426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3667212/2507447237.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_indices = [node_id_to_index[node_id] for node_id in filtered_labels_df['protein']]\n",
    "print(label_indices)\n",
    "num_nodes = len(features_tensor)\n",
    "labels = torch.full((num_nodes,), -1, dtype=torch.long)\n",
    "for i, index in enumerate(filtered_labels_df['Label']):\n",
    "    labels[label_indices[i]] = index\n",
    "\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d33ee91-59f5-4218-96e2-60190520a7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([69877, 768]) torch.float32\n",
      "edge_index: torch.Size([2, 477028]) torch.int64\n",
      "labels: torch.Size([69877]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "data = Data(x=features_tensor, edge_index=edge_index, y=labels_tensor)\n",
    "\n",
    "print(\"x:\", data.x.shape, data.x.dtype)\n",
    "print(\"edge_index:\", data.edge_index.shape, data.edge_index.dtype)\n",
    "print(\"labels:\", data.y.shape, data.y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e713a4-88eb-4611-91fc-c3ca553226a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, num_layers, in_dim, num_hidden, num_classes, heads, activation, dropout, negative_slope, residual):\n",
    "        super(GAT, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "\n",
    "        # Input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads=heads[0],\n",
    "            dropout=dropout, negative_slope=negative_slope, concat=True, add_self_loops=True))\n",
    "\n",
    "        # Hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # Due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads=heads[l],\n",
    "                dropout=dropout, negative_slope=negative_slope, concat=True, add_self_loops=True))\n",
    "\n",
    "        # Output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads=heads[-1],\n",
    "            dropout=dropout, negative_slope=negative_slope, concat=False, add_self_loops=True))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = x\n",
    "        for l, layer in enumerate(self.gat_layers[:-1]):\n",
    "            h = layer(h, edge_index)\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            if l < self.num_layers - 1:\n",
    "                h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Output projection\n",
    "        logits = self.gat_layers[-1](h, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bdf4d93-db76-481a-babc-c745758e0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear, ModuleList, Dropout\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes, num_layers, activation, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.convs = ModuleList([GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers - 2)])\n",
    "        self.conv_last = GCNConv(hidden_dim, num_classes)\n",
    "        self.activation = activation\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 输入层\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 隐藏层\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # 输出层\n",
    "        x = self.conv_last(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ed346d-cd68-44e9-9878-8dba6c95b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    r\"\"\"Computes the accuracy of correct predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    return (pred == target).sum().item() / target.numel()\n",
    "\n",
    "\n",
    "\n",
    "def true_positive(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of true positive predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred == i) & (target == i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def true_negative(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of true negative predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred != i) & (target != i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def false_positive(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of false positive predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred == i) & (target != i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def false_negative(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of false negative predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred != i) & (target == i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def precision(pred, target, num_classes):\n",
    "    r\"\"\"Computes the precision:\n",
    "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
    "    fp = false_positive(pred, target, num_classes).to(torch.float)\n",
    "\n",
    "    out = tp / (tp + fp)\n",
    "    out[torch.isnan(out)] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def recall(pred, target, num_classes):\n",
    "    r\"\"\"Computes the recall:\n",
    "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
    "    fn = false_negative(pred, target, num_classes).to(torch.float)\n",
    "\n",
    "    out = tp / (tp + fn)\n",
    "    out[torch.isnan(out)] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(pred, target, num_classes):\n",
    "    r\"\"\"Computes the :math:`F_1` score:\n",
    "    :math:`2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}\n",
    "    {\\mathrm{precision}+\\mathrm{recall}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    prec = precision(pred, target, num_classes)\n",
    "    rec = recall(pred, target, num_classes)\n",
    "\n",
    "    score = 2 * (prec * rec) / (prec + rec)\n",
    "    score[torch.isnan(score)] = 0\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b03b1df9-611e-4e76-aca4-c8180e726085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "def train_model_scheduler(model, masked_features, labels, edge_index, optimizer, criterion, scheduler, train_mask):\n",
    "    model.train()  # 设置模型为训练模\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index)  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    scheduler.step(loss)\n",
    "    return loss.item()\n",
    "\n",
    "def train_model(model, masked_features, labels, edge_index, optimizer, criterion, train_mask):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index) # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, features, labels, edge_index, mask):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        # 获取模型输出，这里假设输出已经是经过sigmoid的概率\n",
    "        probabilities = model(features, edge_index)\n",
    "        if probabilities.shape[1] == 2:  # 假设有两个输出（每个类一个概率）\n",
    "            positive_probs = probabilities[mask, 1]  # 选择正类概率\n",
    "        else:\n",
    "            positive_probs = probabilities[mask]  # 如果只有一个输出，假设已经是正类概率\n",
    "        val_f1 = torch.mean(f1_score(torch.argmax(probabilities[mask],dim=1), labels[mask], num_classes=2)).cpu().numpy()\n",
    "        auc_score = roc_auc_score(labels[mask].cpu().numpy(), positive_probs.cpu().numpy())\n",
    "    return val_f1, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8cd505-d422-4941-8112-71d69d4b13ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 实例化模型\n",
    "device = torch.device('cuda:1')\n",
    "data = data.to(device)\n",
    "model = GCN(num_features=data.x.shape[1], hidden_dim=64, num_classes=2, num_layers=2, activation=F.relu, dropout=0.5)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=100, verbose=True)\n",
    "\n",
    "\n",
    "labeled_indices = label_indices\n",
    "random.shuffle(labeled_indices)\n",
    "num_labeled = len(labeled_indices)\n",
    "num_train = int(num_labeled * 0.8)\n",
    "num_test = num_labeled - num_train\n",
    "print(num_test)\n",
    "\n",
    "# 创建训练和测试掩码\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[labeled_indices[:num_train]] = True\n",
    "test_mask[labeled_indices[num_train:num_train+num_test]] = True\n",
    "print(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64351bc-b466-4947-aff1-26dc9ae68caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "print(num_train)\n",
    "print(train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cb2241c-e460-4374-afb1-dcd5814e64dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss:0.9378, Macro_F1: 0.5835, AUC_score: 0.8060\n",
      "Epoch 50: Train Loss:0.1680, Macro_F1: 0.9492, AUC_score: 0.9578\n",
      "Epoch 100: Train Loss:0.0975, Macro_F1: 0.9456, AUC_score: 0.9625\n",
      "Epoch 150: Train Loss:0.0541, Macro_F1: 0.9347, AUC_score: 0.9643\n",
      "Epoch 200: Train Loss:0.0433, Macro_F1: 0.9529, AUC_score: 0.9705\n",
      "Epoch 250: Train Loss:0.0364, Macro_F1: 0.9273, AUC_score: 0.9647\n",
      "Epoch 300: Train Loss:0.0593, Macro_F1: 0.9383, AUC_score: 0.9707\n",
      "Epoch 350: Train Loss:0.0263, Macro_F1: 0.9420, AUC_score: 0.9706\n",
      "Epoch 400: Train Loss:0.0666, Macro_F1: 0.9456, AUC_score: 0.9748\n",
      "Epoch 450: Train Loss:0.0235, Macro_F1: 0.9308, AUC_score: 0.9717\n",
      "Epoch 00453: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 500: Train Loss:0.0180, Macro_F1: 0.9383, AUC_score: 0.9759\n",
      "Epoch 550: Train Loss:0.0168, Macro_F1: 0.9493, AUC_score: 0.9765\n",
      "Epoch 600: Train Loss:0.0163, Macro_F1: 0.9384, AUC_score: 0.9761\n",
      "Epoch 650: Train Loss:0.0477, Macro_F1: 0.9347, AUC_score: 0.9739\n",
      "Epoch 00665: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 700: Train Loss:0.0234, Macro_F1: 0.9456, AUC_score: 0.9749\n",
      "Epoch 750: Train Loss:0.0290, Macro_F1: 0.9456, AUC_score: 0.9744\n",
      "Epoch 00766: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 800: Train Loss:0.0353, Macro_F1: 0.9492, AUC_score: 0.9741\n",
      "Epoch 850: Train Loss:0.0211, Macro_F1: 0.9456, AUC_score: 0.9739\n",
      "Epoch 900: Train Loss:0.0168, Macro_F1: 0.9456, AUC_score: 0.9742\n",
      "Epoch 00933: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 950: Train Loss:0.0185, Macro_F1: 0.9492, AUC_score: 0.9745\n",
      "Epoch 1000: Train Loss:0.0167, Macro_F1: 0.9492, AUC_score: 0.9745\n",
      "Epoch 01034: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 1050: Train Loss:0.0116, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1100: Train Loss:0.0189, Macro_F1: 0.9492, AUC_score: 0.9745\n",
      "Epoch 01135: reducing learning rate of group 0 to 3.2000e-07.\n",
      "Epoch 1150: Train Loss:0.0189, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1200: Train Loss:0.0328, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 01236: reducing learning rate of group 0 to 6.4000e-08.\n",
      "Epoch 1250: Train Loss:0.0151, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1300: Train Loss:0.0199, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 01337: reducing learning rate of group 0 to 1.2800e-08.\n",
      "Epoch 1350: Train Loss:0.0152, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1400: Train Loss:0.0143, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 01438: reducing learning rate of group 0 to 2.5600e-09.\n",
      "Epoch 1450: Train Loss:0.0091, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1500: Train Loss:0.0192, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1550: Train Loss:0.0156, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1600: Train Loss:0.0161, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1650: Train Loss:0.0146, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1700: Train Loss:0.0216, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1750: Train Loss:0.0174, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1800: Train Loss:0.0182, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1850: Train Loss:0.0205, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1900: Train Loss:0.0161, Macro_F1: 0.9492, AUC_score: 0.9746\n",
      "Epoch 1950: Train Loss:0.0167, Macro_F1: 0.9492, AUC_score: 0.9746\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model_scheduler(model, data.x, data.y, data.edge_index, optimizer, loss_fn, scheduler, train_mask)\n",
    "    test_f1, test_auc = evaluate_model(model, data.x, data.y, data.edge_index, test_mask)\n",
    "    \n",
    "    if epoch % 50 == 0: \n",
    "        print(f'Epoch {epoch}: Train Loss:{train_loss:.4f}, Macro_F1: {test_f1:.4f}, AUC_score: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a52c63-d68f-4e66-af7c-0a0d87156302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
