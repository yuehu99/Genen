{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "494013c5-2466-42a5-a0f0-76d31ce62ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89641/2362945497.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import obonet\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0e2fdde-37be-4252-b8d4-5b9c734037f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Source      Target\n",
      "0      GO:0000001  GO:0048308\n",
      "1      GO:0000001  GO:0048311\n",
      "2      GO:0000002  GO:0007005\n",
      "3      GO:0000003  GO:0008150\n",
      "4      GO:0000006  GO:0005385\n",
      "...           ...         ...\n",
      "83792  GO:2001317  GO:0034309\n",
      "83793  GO:2001317  GO:0042181\n",
      "83794  GO:2001317  GO:0120255\n",
      "83795  GO:2001317  GO:1901362\n",
      "83796  GO:2001317  GO:2001316\n",
      "\n",
      "[83797 rows x 2 columns]\n",
      "           GO  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
      "0  GO:0000001 -1.168093 -0.355214  0.265877 -0.710051  0.515028 -0.525165   \n",
      "1  GO:0000002 -1.185879 -0.098765  0.388240 -0.295556  0.327296 -0.119842   \n",
      "2  GO:0000003  0.063323 -0.199995  0.151511 -0.942141  0.109313  0.015316   \n",
      "3  GO:0000005  0.163135  0.301527  0.219680  0.094342 -0.129769  0.225696   \n",
      "4  GO:0000006 -0.641113 -0.541363  0.413941  0.699345  0.461507 -0.497388   \n",
      "\n",
      "   feature7  feature8  feature9  ...  feature759  feature760  feature761  \\\n",
      "0 -0.186588 -0.161192  0.186984  ...   -1.350874   -0.991801   -0.648123   \n",
      "1  0.399882 -0.035890  0.853417  ...   -1.086927   -0.842870   -0.385764   \n",
      "2  0.633298  0.507875  0.665548  ...    0.174185    0.351648    0.138497   \n",
      "3  0.357577  0.819992  0.852388  ...   -0.084025   -0.291103   -0.003621   \n",
      "4 -0.044589 -0.655766 -0.596647  ...   -0.561434    0.246475   -0.029871   \n",
      "\n",
      "   feature762  feature763  feature764  feature765  feature766  feature767  \\\n",
      "0   -0.361629   -0.914965   -0.506993    0.389760    0.207266    0.070705   \n",
      "1    0.175797   -1.223772   -0.999628    0.101473   -0.051212    0.048775   \n",
      "2    0.119273   -0.295167   -0.331179    0.102570   -0.524301   -0.139264   \n",
      "3    0.245929   -0.443244    0.229245   -0.685159   -0.725621    0.285964   \n",
      "4   -0.212828   -0.985273    0.677472    0.582681    0.299317   -0.131577   \n",
      "\n",
      "   feature768  \n",
      "0    0.938593  \n",
      "1    0.780470  \n",
      "2    0.761573  \n",
      "3    0.313211  \n",
      "4    0.739702  \n",
      "\n",
      "[5 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "GO_graph = obonet.read_obo(\"GNN/go-basic.obo\")\n",
    "\n",
    "go_edges = []\n",
    "for u, v, data in GO_graph.edges(data=True):\n",
    "    go_edges.append([u, v])\n",
    "go_edges_df = pd.DataFrame(go_edges, columns=['Source', 'Target']).dropna()\n",
    "print(go_edges_df)\n",
    "col_name = ['GO']\n",
    "for i in range(1,769):\n",
    "  col_name.append('feature'+str(i))\n",
    "go_features_df = pd.read_csv(\"GNN/go_terms_embeddings.csv\", skiprows=1, names=col_name).dropna()\n",
    "print(go_features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52fea6b-9319-484e-8c87-babe5a97a4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  protein  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
      "0     FES  0.339602 -0.030744 -0.901381  0.100888  0.886443  0.383596   \n",
      "1  HADHA  -0.131799 -0.025745 -0.677301 -0.053545  0.971046  0.180315   \n",
      "2  SLC7A7  0.385693 -0.070692 -0.847796 -0.022054  0.959772  0.085487   \n",
      "3    LCK   0.650428  0.014479 -0.866163  0.053508  0.951529  0.269402   \n",
      "4   HSPA2  0.322262  0.017484 -0.849302  0.046401  0.920429  0.463832   \n",
      "\n",
      "   feature7  feature8  feature9  ...  feature759  feature760  feature761  \\\n",
      "0 -0.192082 -0.032063 -0.154869  ...   -0.549204   -0.856123    0.714672   \n",
      "1 -0.028189 -0.077389 -0.095152  ...    0.927885   -0.817812    0.809631   \n",
      "2  0.076455 -0.003006 -0.032268  ...    0.941094   -0.912443    0.789828   \n",
      "3 -0.214788  0.045179 -0.506429  ...   -0.576739   -0.969558    0.916549   \n",
      "4 -0.050414 -0.033398  0.387791  ...    0.387301   -0.860696    0.678607   \n",
      "\n",
      "   feature762  feature763  feature764  feature765  feature766  feature767  \\\n",
      "0   -0.046649   -0.894424   -0.001815    0.739485    0.015581   -0.023863   \n",
      "1   -0.005827   -0.848839    0.024516    0.526404   -0.039926   -0.102787   \n",
      "2    0.046979   -0.715636    0.085842    0.150494    0.025392   -0.066035   \n",
      "3   -0.080332   -0.927649   -0.047398    0.741663   -0.000096   -0.096318   \n",
      "4   -0.060695   -0.945793    0.040472    0.831079   -0.001711   -0.079842   \n",
      "\n",
      "   feature768  \n",
      "0   -0.022002  \n",
      "1   -0.026980  \n",
      "2   -0.028283  \n",
      "3   -0.056501  \n",
      "4   -0.011189  \n",
      "\n",
      "[5 rows x 769 columns]\n",
      "         Target      Source\n",
      "0         MT-TF  GO:0030533\n",
      "1         MT-TF  GO:0006412\n",
      "4       MT-RNR2  GO:0003735\n",
      "5       MT-RNR2  GO:0005840\n",
      "6        MT-TL1  GO:0030533\n",
      "...         ...         ...\n",
      "456584  PLEKHM2  GO:0032880\n",
      "456585  PLEKHM2  GO:0010008\n",
      "456586  PLEKHM2  GO:0019894\n",
      "456587  PLEKHM2  GO:0032418\n",
      "456588  PLEKHM2  GO:0042267\n",
      "\n",
      "[393231 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "col_name = ['protein']\n",
    "for i in range(1,769):\n",
    "  col_name.append('feature'+str(i))\n",
    "gene_features_df = pd.read_csv('GNN/gene_embedding_GeneLLM_2.csv', header=None, names=col_name).dropna()\n",
    "print(gene_features_df.head())\n",
    "\n",
    "col_name = ['Target', 'Source']\n",
    "go_protein_df = pd.read_csv(\n",
    "    \"GNN/mart_export.txt\", \n",
    "    skiprows=1, \n",
    "    names=col_name, \n",
    "    usecols=[1, 2]  # 使用列的索引来指定\n",
    ").dropna()\n",
    "print(go_protein_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0687af1-b46b-4d55-beab-110c6f93dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature759</th>\n",
       "      <th>feature760</th>\n",
       "      <th>feature761</th>\n",
       "      <th>feature762</th>\n",
       "      <th>feature763</th>\n",
       "      <th>feature764</th>\n",
       "      <th>feature765</th>\n",
       "      <th>feature766</th>\n",
       "      <th>feature767</th>\n",
       "      <th>feature768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FES</td>\n",
       "      <td>0.339602</td>\n",
       "      <td>-0.030744</td>\n",
       "      <td>-0.901381</td>\n",
       "      <td>0.100888</td>\n",
       "      <td>0.886443</td>\n",
       "      <td>0.383596</td>\n",
       "      <td>-0.192082</td>\n",
       "      <td>-0.032063</td>\n",
       "      <td>-0.154869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.549204</td>\n",
       "      <td>-0.856123</td>\n",
       "      <td>0.714672</td>\n",
       "      <td>-0.046649</td>\n",
       "      <td>-0.894424</td>\n",
       "      <td>-0.001815</td>\n",
       "      <td>0.739485</td>\n",
       "      <td>0.015581</td>\n",
       "      <td>-0.023863</td>\n",
       "      <td>-0.022002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HADHA</td>\n",
       "      <td>-0.131799</td>\n",
       "      <td>-0.025745</td>\n",
       "      <td>-0.677301</td>\n",
       "      <td>-0.053545</td>\n",
       "      <td>0.971046</td>\n",
       "      <td>0.180315</td>\n",
       "      <td>-0.028189</td>\n",
       "      <td>-0.077389</td>\n",
       "      <td>-0.095152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927885</td>\n",
       "      <td>-0.817812</td>\n",
       "      <td>0.809631</td>\n",
       "      <td>-0.005827</td>\n",
       "      <td>-0.848839</td>\n",
       "      <td>0.024516</td>\n",
       "      <td>0.526404</td>\n",
       "      <td>-0.039926</td>\n",
       "      <td>-0.102787</td>\n",
       "      <td>-0.026980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLC7A7</td>\n",
       "      <td>0.385693</td>\n",
       "      <td>-0.070692</td>\n",
       "      <td>-0.847796</td>\n",
       "      <td>-0.022054</td>\n",
       "      <td>0.959772</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.076455</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>-0.032268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941094</td>\n",
       "      <td>-0.912443</td>\n",
       "      <td>0.789828</td>\n",
       "      <td>0.046979</td>\n",
       "      <td>-0.715636</td>\n",
       "      <td>0.085842</td>\n",
       "      <td>0.150494</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>-0.066035</td>\n",
       "      <td>-0.028283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LCK</td>\n",
       "      <td>0.650428</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>-0.866163</td>\n",
       "      <td>0.053508</td>\n",
       "      <td>0.951529</td>\n",
       "      <td>0.269402</td>\n",
       "      <td>-0.214788</td>\n",
       "      <td>0.045179</td>\n",
       "      <td>-0.506429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576739</td>\n",
       "      <td>-0.969558</td>\n",
       "      <td>0.916549</td>\n",
       "      <td>-0.080332</td>\n",
       "      <td>-0.927649</td>\n",
       "      <td>-0.047398</td>\n",
       "      <td>0.741663</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.096318</td>\n",
       "      <td>-0.056501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSPA2</td>\n",
       "      <td>0.322262</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>-0.849302</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.920429</td>\n",
       "      <td>0.463832</td>\n",
       "      <td>-0.050414</td>\n",
       "      <td>-0.033398</td>\n",
       "      <td>0.387791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387301</td>\n",
       "      <td>-0.860696</td>\n",
       "      <td>0.678607</td>\n",
       "      <td>-0.060695</td>\n",
       "      <td>-0.945793</td>\n",
       "      <td>0.040472</td>\n",
       "      <td>0.831079</td>\n",
       "      <td>-0.001711</td>\n",
       "      <td>-0.079842</td>\n",
       "      <td>-0.011189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47590</th>\n",
       "      <td>GO:2001313</td>\n",
       "      <td>0.174428</td>\n",
       "      <td>0.194728</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>0.282102</td>\n",
       "      <td>-0.713190</td>\n",
       "      <td>-0.272055</td>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.129901</td>\n",
       "      <td>-0.983496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500545</td>\n",
       "      <td>0.429651</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.464941</td>\n",
       "      <td>-0.740187</td>\n",
       "      <td>0.179149</td>\n",
       "      <td>-0.960807</td>\n",
       "      <td>-0.746958</td>\n",
       "      <td>1.069112</td>\n",
       "      <td>-0.848182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47591</th>\n",
       "      <td>GO:2001314</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.306214</td>\n",
       "      <td>-0.254303</td>\n",
       "      <td>0.253673</td>\n",
       "      <td>-0.533680</td>\n",
       "      <td>-0.269355</td>\n",
       "      <td>0.150939</td>\n",
       "      <td>-0.229323</td>\n",
       "      <td>-1.078991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042979</td>\n",
       "      <td>0.134560</td>\n",
       "      <td>-0.356661</td>\n",
       "      <td>-0.381828</td>\n",
       "      <td>-0.638338</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>-0.788312</td>\n",
       "      <td>-0.683442</td>\n",
       "      <td>1.087031</td>\n",
       "      <td>-0.593092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47592</th>\n",
       "      <td>GO:2001315</td>\n",
       "      <td>0.027134</td>\n",
       "      <td>0.241391</td>\n",
       "      <td>-0.227353</td>\n",
       "      <td>0.317366</td>\n",
       "      <td>-0.726657</td>\n",
       "      <td>-0.197968</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>-0.954113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349853</td>\n",
       "      <td>0.370059</td>\n",
       "      <td>-0.144606</td>\n",
       "      <td>-0.493184</td>\n",
       "      <td>-0.655063</td>\n",
       "      <td>0.217335</td>\n",
       "      <td>-0.841272</td>\n",
       "      <td>-0.821077</td>\n",
       "      <td>1.036363</td>\n",
       "      <td>-0.836614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47593</th>\n",
       "      <td>GO:2001316</td>\n",
       "      <td>0.139543</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.899480</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>0.576852</td>\n",
       "      <td>0.330342</td>\n",
       "      <td>0.916943</td>\n",
       "      <td>0.012306</td>\n",
       "      <td>-0.020316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354748</td>\n",
       "      <td>-0.083168</td>\n",
       "      <td>0.043640</td>\n",
       "      <td>-0.663565</td>\n",
       "      <td>0.543016</td>\n",
       "      <td>-0.652230</td>\n",
       "      <td>-1.427882</td>\n",
       "      <td>-0.985257</td>\n",
       "      <td>1.673561</td>\n",
       "      <td>0.109659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47594</th>\n",
       "      <td>GO:2001317</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>0.090899</td>\n",
       "      <td>0.888541</td>\n",
       "      <td>0.309920</td>\n",
       "      <td>0.403966</td>\n",
       "      <td>0.202783</td>\n",
       "      <td>0.706517</td>\n",
       "      <td>-0.017584</td>\n",
       "      <td>-0.171057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.544680</td>\n",
       "      <td>-0.046654</td>\n",
       "      <td>0.262865</td>\n",
       "      <td>-0.767305</td>\n",
       "      <td>0.753788</td>\n",
       "      <td>-0.577503</td>\n",
       "      <td>-1.194910</td>\n",
       "      <td>-0.799556</td>\n",
       "      <td>1.519368</td>\n",
       "      <td>0.263210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62045 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          protein  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0             FES  0.339602 -0.030744 -0.901381  0.100888  0.886443  0.383596   \n",
       "1          HADHA  -0.131799 -0.025745 -0.677301 -0.053545  0.971046  0.180315   \n",
       "2          SLC7A7  0.385693 -0.070692 -0.847796 -0.022054  0.959772  0.085487   \n",
       "3            LCK   0.650428  0.014479 -0.866163  0.053508  0.951529  0.269402   \n",
       "4           HSPA2  0.322262  0.017484 -0.849302  0.046401  0.920429  0.463832   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "47590  GO:2001313  0.174428  0.194728 -0.284376  0.282102 -0.713190 -0.272055   \n",
       "47591  GO:2001314  0.025886  0.306214 -0.254303  0.253673 -0.533680 -0.269355   \n",
       "47592  GO:2001315  0.027134  0.241391 -0.227353  0.317366 -0.726657 -0.197968   \n",
       "47593  GO:2001316  0.139543  0.028883  0.899480  0.152932  0.576852  0.330342   \n",
       "47594  GO:2001317  0.083064  0.090899  0.888541  0.309920  0.403966  0.202783   \n",
       "\n",
       "       feature7  feature8  feature9  ...  feature759  feature760  feature761  \\\n",
       "0     -0.192082 -0.032063 -0.154869  ...   -0.549204   -0.856123    0.714672   \n",
       "1     -0.028189 -0.077389 -0.095152  ...    0.927885   -0.817812    0.809631   \n",
       "2      0.076455 -0.003006 -0.032268  ...    0.941094   -0.912443    0.789828   \n",
       "3     -0.214788  0.045179 -0.506429  ...   -0.576739   -0.969558    0.916549   \n",
       "4     -0.050414 -0.033398  0.387791  ...    0.387301   -0.860696    0.678607   \n",
       "...         ...       ...       ...  ...         ...         ...         ...   \n",
       "47590  0.121190  0.129901 -0.983496  ...    0.500545    0.429651   -0.292929   \n",
       "47591  0.150939 -0.229323 -1.078991  ...    0.042979    0.134560   -0.356661   \n",
       "47592  0.045653  0.038912 -0.954113  ...    0.349853    0.370059   -0.144606   \n",
       "47593  0.916943  0.012306 -0.020316  ...   -0.354748   -0.083168    0.043640   \n",
       "47594  0.706517 -0.017584 -0.171057  ...   -0.544680   -0.046654    0.262865   \n",
       "\n",
       "       feature762  feature763  feature764  feature765  feature766  feature767  \\\n",
       "0       -0.046649   -0.894424   -0.001815    0.739485    0.015581   -0.023863   \n",
       "1       -0.005827   -0.848839    0.024516    0.526404   -0.039926   -0.102787   \n",
       "2        0.046979   -0.715636    0.085842    0.150494    0.025392   -0.066035   \n",
       "3       -0.080332   -0.927649   -0.047398    0.741663   -0.000096   -0.096318   \n",
       "4       -0.060695   -0.945793    0.040472    0.831079   -0.001711   -0.079842   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "47590   -0.464941   -0.740187    0.179149   -0.960807   -0.746958    1.069112   \n",
       "47591   -0.381828   -0.638338    0.077176   -0.788312   -0.683442    1.087031   \n",
       "47592   -0.493184   -0.655063    0.217335   -0.841272   -0.821077    1.036363   \n",
       "47593   -0.663565    0.543016   -0.652230   -1.427882   -0.985257    1.673561   \n",
       "47594   -0.767305    0.753788   -0.577503   -1.194910   -0.799556    1.519368   \n",
       "\n",
       "       feature768  \n",
       "0       -0.022002  \n",
       "1       -0.026980  \n",
       "2       -0.028283  \n",
       "3       -0.056501  \n",
       "4       -0.011189  \n",
       "...           ...  \n",
       "47590   -0.848182  \n",
       "47591   -0.593092  \n",
       "47592   -0.836614  \n",
       "47593    0.109659  \n",
       "47594    0.263210  \n",
       "\n",
       "[62045 rows x 769 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(go_features_df))\n",
    "go_features_df.rename(columns={'GO': 'protein'}, inplace=True)\n",
    "combined_features = pd.concat([gene_features_df, go_features_df])\n",
    "combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f8a168-b51c-442c-8b1e-52833e7450df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Node                                          Embedding\n",
      "0             FES  [0.4438934076953207, 0.6547635781497536, 0.479...\n",
      "1          HADHA   [0.43062846341232963, 0.17973569083045415, 0.6...\n",
      "2          SLC7A7  [0.5660207802974483, 0.9893016741119274, 0.889...\n",
      "3            LCK   [0.05244531785542528, 0.7042113750619634, 0.44...\n",
      "4           HSPA2  [0.06608896989532431, 0.6718893790647981, 0.45...\n",
      "...           ...                                                ...\n",
      "62040  GO:2001313  [0.76197988097058, 0.6578877828420915, 0.55918...\n",
      "62041  GO:2001314  [0.14085847914459715, 0.7352766352762377, 0.59...\n",
      "62042  GO:2001315  [0.829709428784575, 0.4123918009929196, 0.5760...\n",
      "62043  GO:2001316  [0.7240967613247861, 0.5148399788025295, 0.747...\n",
      "62044  GO:2001317  [0.23188587195825383, 0.6366218499635815, 0.99...\n",
      "\n",
      "[62045 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nodes = combined_features['protein']\n",
    "\n",
    "# 定义嵌入的维度\n",
    "embedding_dim = 768\n",
    "\n",
    "# 生成随机嵌入\n",
    "node_embeddings = {node: np.random.rand(embedding_dim) for node in nodes}\n",
    "\n",
    "# 创建列表，每个元素为一个包含节点名和嵌入的字典\n",
    "data = [{'Node': node, 'Embedding': embedding} for node, embedding in node_embeddings.items()]\n",
    "\n",
    "# 转换为DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 查看DataFrame的前几行\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acc9fdf-d51f-4168-8781-63d3168ae037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89641/2498144971.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  features_tensor = torch.tensor(df['Embedding'].tolist(), dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4439, 0.6548, 0.4793,  ..., 0.8343, 0.8348, 0.1999],\n",
       "        [0.4306, 0.1797, 0.6233,  ..., 0.3515, 0.3180, 0.4356],\n",
       "        [0.5660, 0.9893, 0.8894,  ..., 0.5455, 0.6846, 0.7396],\n",
       "        ...,\n",
       "        [0.8297, 0.4124, 0.5761,  ..., 0.9669, 0.6896, 0.4834],\n",
       "        [0.7241, 0.5148, 0.7475,  ..., 0.6062, 0.8720, 0.7089],\n",
       "        [0.2319, 0.6366, 0.9992,  ..., 0.6943, 0.1489, 0.1729]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_tensor = torch.tensor(df['Embedding'].tolist(), dtype=torch.float)\n",
    "features_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f429722b-5b36-4a6d-8565-c8cce183176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_edges_df = pd.read_csv('GNN/protein_interactions.csv', usecols=[0, 1], names=col_name).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2aa882c-744f-42d4-9f1c-309ff7edfd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>GO:0030533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT-TF</td>\n",
       "      <td>GO:0006412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT-RNR2</td>\n",
       "      <td>GO:0003735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MT-RNR2</td>\n",
       "      <td>GO:0005840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MT-TL1</td>\n",
       "      <td>GO:0030533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715124</th>\n",
       "      <td>LDB1</td>\n",
       "      <td>SAMD14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715125</th>\n",
       "      <td>LDB1</td>\n",
       "      <td>KDM6B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715126</th>\n",
       "      <td>LDB1</td>\n",
       "      <td>WWP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715127</th>\n",
       "      <td>LDB1</td>\n",
       "      <td>VPS33B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13715128</th>\n",
       "      <td>LDB1</td>\n",
       "      <td>NDST2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13544448 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Target      Source\n",
       "0           MT-TF  GO:0030533\n",
       "1           MT-TF  GO:0006412\n",
       "4         MT-RNR2  GO:0003735\n",
       "5         MT-RNR2  GO:0005840\n",
       "6          MT-TL1  GO:0030533\n",
       "...           ...         ...\n",
       "13715124     LDB1      SAMD14\n",
       "13715125     LDB1       KDM6B\n",
       "13715126     LDB1        WWP2\n",
       "13715127     LDB1      VPS33B\n",
       "13715128     LDB1       NDST2\n",
       "\n",
       "[13544448 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_edges = pd.concat([go_protein_df, go_edges_df, gene_edges_df])\n",
    "#combined_edges = combined_edges[['Source', 'Target']]\n",
    "combined_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302ee57b-8278-4a8f-a7ec-59415214614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_in_features = set(combined_features['protein'])\n",
    "\n",
    "filtered_edges_df = combined_edges[\n",
    "    combined_edges['Source'].isin(nodes_in_features) & combined_edges['Target'].isin(nodes_in_features)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7ad612-6970-48f5-895d-c01adc68b0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24323, 17460, 27132,  ...,   947,  6874, 13222],\n",
       "        [ 2077,  2077,  2077,  ..., 10107, 10107, 10107]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_id_to_index = {node_id: i for i, node_id in enumerate(combined_features['protein'])}\n",
    "# 确保edge_index是按照这个新的索引顺序排列的\n",
    "source_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['Source']]\n",
    "target_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['Target']]\n",
    "edge_index = torch.tensor([source_indices, target_indices], dtype=torch.long)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecbfcb19-7c04-4bf7-9665-855756502420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>protein</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>Label</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Count_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ERAP2</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NDNF</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>1374</td>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>1375</td>\n",
       "      <td>RPS9</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>1376</td>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>1377</td>\n",
       "      <td>FBN3</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1378</td>\n",
       "      <td>BDH2</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   protein Solubility  Label  Word_Count  Count_Category\n",
       "0              0     ERAP2   Membrane      0         117               0\n",
       "1              1  ADAMTSL5    Soluble      1          28               1\n",
       "2              2   TBC1D30   Membrane      0          55               0\n",
       "3              3    KCNK18   Membrane      0         184               0\n",
       "4              4      NDNF    Soluble      1         129               0\n",
       "...          ...       ...        ...    ...         ...             ...\n",
       "1374        1374   TRABD2B   Membrane      0          96               0\n",
       "1375        1375      RPS9    Soluble      1         205               0\n",
       "1376        1376  SLC22A16   Membrane      0          93               0\n",
       "1377        1377      FBN3    Soluble      1          90               0\n",
       "1378        1378      BDH2    Soluble      1         102               0\n",
       "\n",
       "[1379 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('GNN/new_labels.csv')\n",
    "labels_df.rename(columns={'Gene name': 'protein'}, inplace=True)\n",
    "labels_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa88fb50-5adf-41bd-9bfc-92fd6e070f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 81, 93, 94, 100, 116, 129, 142, 148, 149, 157, 167, 170, 202, 228, 236, 241, 243, 255, 258, 276, 281, 287, 294, 305, 319, 321, 334, 340, 369, 373, 375, 383, 384, 399, 402, 418, 447, 455, 474, 483, 484, 490, 498, 511, 518, 526, 558, 569, 585, 586, 587, 593, 594, 595, 596, 599, 615, 641, 653, 654, 664, 682, 736, 754, 762, 764, 773, 777, 781, 833, 852, 894, 895, 899, 915, 917, 938, 944, 957, 982, 983, 997, 1003, 1019, 1040, 1047, 1053, 1062, 1064, 1065, 1067, 1074, 1075, 1078, 1079, 1105, 1108, 1115, 1116, 1120, 1124, 1131, 1136, 1137, 1143, 1157, 1170, 1173, 1183, 1195, 1196, 1197, 1215, 1235, 1236, 1237, 1243, 1256, 1261, 1262, 1273, 1274, 1277, 1311, 1315, 1327, 1333, 1347, 1363, 1371, 1377, 1378, 1383, 1392, 1397, 1426, 1427, 1431, 1435, 1444, 1445, 1469, 1470, 1475, 1484, 1489, 1492, 1493, 1521, 1527, 1540, 1548, 1559, 1575, 1593, 1606, 1609, 1614, 1617, 1619, 1637, 1638, 1645, 1674, 1681, 1710, 1720, 1733, 1736, 1737, 1759, 1776, 1795, 1807, 1823, 1833, 1834, 1844, 1848, 1849, 1852, 1854, 1882, 1893, 1895, 1898, 1914, 1917, 1923, 1927, 1960, 1970, 1972, 1978, 1986, 1995, 2015, 2016, 2022, 2031, 2046, 2048, 2071, 2096, 2097, 2099, 2101, 2104, 2109, 2112, 2115, 2117, 2119, 2140, 2151, 2154, 2166, 2188, 2196, 2209, 2214, 2227, 2231, 2238, 2250, 2256, 2265, 2273, 2274, 2277, 2281, 2283, 2284, 2286, 2292, 2293, 2302, 2308, 2316, 2326, 2337, 2353, 2354, 2358, 2362, 2364, 2365, 2370, 2372, 2400, 2417, 2419, 2421, 2422, 2424, 2427, 2455, 2465, 2476, 2481, 2489, 2496, 2505, 2532, 2533, 2535, 2540, 2551, 2556, 2589, 2620, 2625, 2630, 2634, 2660, 2672, 2676, 2686, 2701, 2705, 2708, 2716, 2730, 2738, 2767, 2770, 2785, 2788, 2802, 2804, 2819, 2823, 2827, 2836, 2842, 2862, 2871, 2879, 2888, 2896, 2903, 2907, 2915, 2927, 2928, 2929, 2937, 2950, 2957, 2958, 2960, 2982, 2986, 2995, 3000, 3013, 3014, 3021, 3024, 3027, 3037, 3043, 3044, 3054, 3057, 3064, 3084, 3092, 3099, 3117, 3123, 3147, 3150, 3159, 3180, 3186, 3217, 3240, 3244, 3255, 3268, 3272, 3285, 3291, 3305, 3319, 3325, 3326, 3327, 3330, 3353, 3356, 3382, 3389, 3393, 3408, 3410, 3417, 3433, 3454, 3456, 3465, 3486, 3502, 3511, 3519, 3530, 3535, 3536, 3538, 3543, 3584, 3615, 3619, 3620, 3630, 3647, 3663, 3680, 3684, 3692, 3706, 3707, 3715, 3727, 3747, 3751, 3752, 3754, 3774, 3779, 3781, 3783, 3785, 3786, 3792, 3797, 3802, 3810, 3829, 3833, 3839, 3850, 3882, 3884, 3886, 3902, 3917, 3921, 3923, 3929, 3943, 3949, 3959, 3960, 3968, 3969, 3977, 3985, 3990, 3991, 3992, 4019, 4025, 4034, 4040, 4048, 4049, 4071, 4102, 4120, 4133, 4159, 4165, 4166, 4169, 4178, 4184, 4185, 4197, 4209, 4225, 4232, 4239, 4249, 4251, 4258, 4288, 4323, 4328, 4332, 4333, 4343, 4351, 4360, 4361, 4365, 4375, 4376, 4387, 4417, 4431, 4433, 4438, 4439, 4440, 4464, 4465, 4484, 4485, 4495, 4500, 4507, 4513, 4520, 4524, 4526, 4539, 4545, 4558, 4560, 4565, 4572, 4607, 4616, 4630, 4637, 4653, 4656, 4668, 4676, 4711, 4712, 4716, 4721, 4751, 4760, 4776, 4780, 4783, 4792, 4795, 4796, 4800, 4804, 4806, 4815, 4833, 4836, 4840, 4853, 4882, 4888, 4897, 4913, 4915, 4926, 4930, 4935, 4961, 4963, 4995, 4999, 5006, 5013, 5020, 5041, 5061, 5072, 5077, 5079, 5083, 5085, 5124, 5139, 5144, 5146, 5151, 5154, 5167, 5170, 5173, 5178, 5192, 5209, 5216, 5218, 5226, 5228, 5233, 5242, 5243, 5253, 5264, 5271, 5278, 5280, 5298, 5306, 5312, 5327, 5351, 5379, 5383, 5396, 5399, 5405, 5410, 5418, 5437, 5486, 5488, 5506, 5510, 5512, 5513, 5522, 5555, 5556, 5566, 5569, 5570, 5575, 5582, 5586, 5589, 5593, 5628, 5634, 5635, 5644, 5670, 5674, 5687, 5693, 5702, 5703, 5710, 5713, 5721, 5736, 5738, 5784, 5785, 5787, 5792, 5793, 5820, 5823, 5866, 5884, 5890, 5898, 5899, 5900, 5902, 5913, 5943, 5954, 5958, 5963, 5985, 5991, 5992, 6006, 6011, 6038, 6043, 6057, 6058, 6064, 6066, 6078, 6081, 6094, 6099, 6101, 6112, 6119, 6120, 6127, 6128, 6131, 6134, 6136, 6168, 6177, 6179, 6196, 6203, 6211, 6223, 6226, 6227, 6239, 6246, 6278, 6301, 6302, 6314, 6319, 6328, 6343, 6377, 6389, 6416, 6426, 6427, 6428, 6436, 6438, 6448, 6460, 6494, 6514, 6516, 6517, 6518, 6527, 6528, 6549, 6556, 6559, 6562, 6567, 6569, 6579, 6583, 6593, 6595, 6606, 6607, 6612, 6623, 6628, 6630, 6639, 6667, 6679, 6681, 6699, 6702, 6703, 6714, 6717, 6728, 6744, 6772, 6774, 6782, 6785, 6792, 6804, 6815, 6819, 6823, 6832, 6844, 6850, 6859, 6865, 6871, 6884, 6885, 6886, 6943, 6947, 6963, 6995, 7000, 7017, 7018, 7019, 7026, 7040, 7047, 7049, 7065, 7067, 7073, 7074, 7081, 7083, 7089, 7093, 7108, 7116, 7125, 7130, 7139, 7151, 7152, 7153, 7157, 7170, 7185, 7189, 7192, 7201, 7202, 7203, 7221, 7252, 7266, 7278, 7280, 7281, 7286, 7296, 7300, 7312, 7313, 7341, 7349, 7357, 7365, 7375, 7377, 7387, 7389, 7390, 7412, 7415, 7420, 7427, 7433, 7440, 7449, 7456, 7465, 7469, 7481, 7510, 7520, 7527, 7528, 7549, 7561, 7563, 7564, 7573, 7590, 7591, 7599, 7609, 7610, 7631, 7634, 7640, 7645, 7653, 7654, 7665, 7688, 7692, 7705, 7715, 7721, 7755, 7760, 7769, 7782, 7783, 7793, 7839, 7865, 7889, 7891, 7892, 7921, 7930, 7956, 7958, 8012, 8013, 8031, 8041, 8046, 8060, 8066, 8073, 8075, 8077, 8078, 8124, 8139, 8156, 8175, 8189, 8196, 8204, 8212, 8215, 8225, 8226, 8228, 8229, 8231, 8234, 8243, 8250, 8262, 8266, 8272, 8285, 8290, 8303, 8305, 8323, 8327, 8329, 8339, 8343, 8348, 8349, 8350, 8351, 8356, 8357, 8360, 8366, 8383, 8386, 8389, 8405, 8413, 8419, 8441, 8447, 8451, 8454, 8467, 8480, 8491, 8492, 8497, 8517, 8519, 8535, 8554, 8557, 8560, 8567, 8568, 8576, 8592, 8595, 8600, 8608, 8631, 8632, 8633, 8641, 8645, 8647, 8653, 8672, 8683, 8691, 8716, 8720, 8727, 8733, 8741, 8746, 8748, 8749, 8786, 8808, 8814, 8815, 8818, 8820, 8826, 8828, 8865, 8903, 8927, 8931, 8942, 8946, 8991, 8998, 9013, 9026, 9027, 9056, 9066, 9085, 9097, 9098, 9115, 9126, 9134, 9135, 9144, 9148, 9165, 9189, 9190, 9225, 9231, 9246, 9263, 9293, 9301, 9302, 9323, 9325, 9364, 9385, 9410, 9416, 9423, 9431, 9435, 9437, 9457, 9500, 9512, 9514, 9517, 9535, 9547, 9552, 9561, 9573, 9589, 9607, 9627, 9638, 9639, 9659, 9682, 9708, 9757, 9772, 9776, 9784, 9800, 9809, 9822, 9823, 9828, 9836, 9852, 9853, 9862, 9875, 9885, 9900, 9908, 9910, 9926, 9937, 9978, 10000, 10010, 10023, 10031, 10038, 10045, 10046, 10053, 10060, 10063, 10075, 10090, 10094, 10119, 10125, 10138, 10146, 10147, 10151, 10158, 10159, 10168, 10172, 10183, 10201, 10217, 10246, 10298, 10300, 10309, 10321, 10323, 10325, 10327, 10364, 10372, 10379, 10390, 10409, 10410, 10411, 10418, 10424, 10432, 10435, 10436, 10443, 10452, 10459, 10479, 10483, 10485, 10500, 10502, 10527, 10534, 10536, 10542, 10552, 10561, 10580, 10581, 10607, 10619, 10622, 10623, 10629, 10655, 10666, 10685, 10686, 10695, 10697, 10699, 10700, 10701, 10705, 10708, 10730, 10732, 10751, 10754, 10764, 10765, 10776, 10779, 10789, 10794, 10825, 10828, 10862, 10877, 10887, 10890, 10905, 10917, 10926, 10934, 10951, 10988, 11000, 11002, 11022, 11028, 11033, 11035, 11040, 11050, 11089, 11108, 11109, 11125, 11140, 11142, 11150, 11164, 11175, 11178, 11184, 11187, 11192, 11210, 11222, 11247, 11248, 11273, 11277, 11278, 11286, 11289, 11296, 11307, 11321, 11324, 11340, 11343, 11345, 11362, 11406, 11407, 11410, 11418, 11428, 11458, 11482, 11492, 11497, 11523, 11533, 11538, 11542, 11548, 11549, 11562, 11572, 11583, 11601, 11609, 11634, 11638, 11655, 11657, 11658, 11676, 11688, 11707, 11711, 11734, 11746, 11749, 11752, 11758, 11774, 11803, 11805, 11810, 11820, 11844, 11887, 11928, 11938, 11951, 11958, 11967, 11984, 11987, 12071, 12080, 12102, 12103, 12107, 12111, 12116, 12124, 12130, 12142, 12151, 12154, 12169, 12174, 12193, 12194, 12199, 12205, 12262, 12271, 12272, 12284, 12289, 12296, 12302, 12304, 12323, 12345, 12348, 12358, 12373, 12386, 12429, 12432, 12457, 12470, 12487, 12488, 12511, 12517, 12578, 12579, 12587, 12593, 12666, 12667, 12684, 12705, 12706, 12760, 12776, 12784, 12805, 12819, 12821, 12848, 12864, 12873, 12889, 12918, 12954, 12955, 12956, 12958, 12959, 12974, 13001, 13003, 13017, 13022, 13042, 13045, 13049, 13078, 13083, 13084, 13088, 13090, 13120, 13130, 13138, 13164, 13165, 13181, 13186, 13192, 13206, 13214, 13243, 13251, 13266, 13292, 13295, 13305, 13314, 13321, 13334, 13394, 13409, 13422, 13443, 13447, 13469, 13502, 13512, 13536, 13559, 13566, 13567, 13571, 13580, 13582, 13586, 13594, 13657, 13662, 13666, 13672, 13673, 13685, 13724, 13727, 13741, 13760, 13779, 13826, 13831, 13838, 13847, 13855, 13858, 13862, 13871, 13872, 13874, 13882, 13892, 13898, 13901, 13906, 13924, 13931, 13936, 13943, 13951, 13965, 13978, 13984, 14012, 14015, 14024, 14036, 14052, 14090, 14117, 14146, 14151, 14162, 14214, 14234, 14240, 14241, 14263, 14268, 14279, 14281, 14288, 14293, 14315, 14317, 14318, 14324, 14325, 14398, 14407, 14426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89641/2534729209.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "label_indices = [node_id_to_index[node_id] for node_id in labels_df['protein']]\n",
    "print(label_indices)\n",
    "num_nodes = len(combined_features)\n",
    "labels = torch.full((num_nodes,), -1, dtype=torch.long)\n",
    "for i, index in enumerate(labels_df['Label']):\n",
    "    labels[label_indices[i]] = index\n",
    "\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cf66463-4033-4718-a37c-f5396958318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([62045, 768]) torch.float32\n",
      "edge_index: torch.Size([2, 9914754]) torch.int64\n",
      "labels: torch.Size([62045]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "data = Data(x=features_tensor, edge_index=edge_index, y=labels_tensor)\n",
    "\n",
    "print(\"x:\", data.x.shape, data.x.dtype)\n",
    "print(\"edge_index:\", data.edge_index.shape, data.edge_index.dtype)\n",
    "print(\"labels:\", data.y.shape, data.y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d031a8e3-77f1-4beb-a8db-5a48194af9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear, ModuleList, Dropout\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes, num_layers, activation, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.convs = ModuleList([GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers - 2)])\n",
    "        self.conv_last = GCNConv(hidden_dim, num_classes)\n",
    "        self.activation = activation\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 输入层\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 隐藏层\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # 输出层\n",
    "        x = self.conv_last(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e654645f-de43-4e9a-9ea5-107e2f478836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    r\"\"\"Computes the accuracy of correct predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    return (pred == target).sum().item() / target.numel()\n",
    "\n",
    "\n",
    "\n",
    "def true_positive(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of true positive predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred == i) & (target == i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def true_negative(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of true negative predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred != i) & (target != i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def false_positive(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of false positive predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred == i) & (target != i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def false_negative(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of false negative predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred != i) & (target == i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def precision(pred, target, num_classes):\n",
    "    r\"\"\"Computes the precision:\n",
    "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
    "    fp = false_positive(pred, target, num_classes).to(torch.float)\n",
    "\n",
    "    out = tp / (tp + fp)\n",
    "    out[torch.isnan(out)] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def recall(pred, target, num_classes):\n",
    "    r\"\"\"Computes the recall:\n",
    "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
    "    fn = false_negative(pred, target, num_classes).to(torch.float)\n",
    "\n",
    "    out = tp / (tp + fn)\n",
    "    out[torch.isnan(out)] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(pred, target, num_classes):\n",
    "    r\"\"\"Computes the :math:`F_1` score:\n",
    "    :math:`2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}\n",
    "    {\\mathrm{precision}+\\mathrm{recall}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    prec = precision(pred, target, num_classes)\n",
    "    rec = recall(pred, target, num_classes)\n",
    "\n",
    "    score = 2 * (prec * rec) / (prec + rec)\n",
    "    score[torch.isnan(score)] = 0\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1aa6d370-98db-4894-a649-21fddbbd393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "def train_model_scheduler(model, masked_features, labels, edge_index, optimizer, criterion, scheduler, train_mask):\n",
    "    model.train()  # 设置模型为训练模\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index)  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    scheduler.step(loss)\n",
    "    return loss.item()\n",
    "\n",
    "def train_model(model, masked_features, labels, edge_index, optimizer, criterion, train_mask):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index) # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, features, labels, edge_index, mask):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        # 获取模型输出，这里假设输出已经是经过sigmoid的概率\n",
    "        probabilities = model(features, edge_index)\n",
    "        if probabilities.shape[1] == 2:  # 假设有两个输出（每个类一个概率）\n",
    "            positive_probs = probabilities[mask, 1]  # 选择正类概率\n",
    "        else:\n",
    "            positive_probs = probabilities[mask]  # 如果只有一个输出，假设已经是正类概率\n",
    "        val_f1 = torch.mean(f1_score(torch.argmax(probabilities[mask],dim=1), labels[mask], num_classes=2)).cpu().numpy()\n",
    "        auc_score = roc_auc_score(labels[mask].cpu().numpy(), positive_probs.cpu().numpy())\n",
    "\n",
    "    return val_f1, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d642bfc8-84b1-4dab-bd9b-ba928ff5fb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 实例化模型\n",
    "device = torch.device('cpu')\n",
    "data = data.to(device)\n",
    "model = GCN(num_features=data.x.shape[1], hidden_dim=64, num_classes=2, num_layers=2, activation=F.relu, dropout=0.5)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=100, verbose=True)\n",
    "\n",
    "\n",
    "labeled_indices = label_indices\n",
    "random.shuffle(labeled_indices)\n",
    "num_labeled = len(labeled_indices)\n",
    "num_train = int(num_labeled * 0.8)\n",
    "num_test = num_labeled - num_train\n",
    "print(num_test)\n",
    "\n",
    "# 创建训练和测试掩码\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[labeled_indices[:num_train]] = True\n",
    "test_mask[labeled_indices[num_train:num_train+num_test]] = True\n",
    "print(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27f6d495-d068-4705-aaa9-f36b721b71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss:0.9474, Macro_F1: 0.3429, AUC_score: 0.5231\n",
      "Epoch 99: Train Loss:0.6797, Macro_F1: 0.3371, AUC_score: 0.5276\n",
      "Epoch 149: Train Loss:0.6938, Macro_F1: 0.3235, AUC_score: 0.5327\n",
      "Epoch 199: Train Loss:0.6827, Macro_F1: 0.5208, AUC_score: 0.5305\n",
      "Epoch 00249: reducing learning rate of group 0 to 2.0000e-03.\n",
      "Epoch 249: Train Loss:0.6716, Macro_F1: 0.6143, AUC_score: 0.5507\n",
      "Epoch 299: Train Loss:0.6754, Macro_F1: 0.6123, AUC_score: 0.5558\n",
      "Epoch 349: Train Loss:0.6704, Macro_F1: 0.5540, AUC_score: 0.5537\n",
      "Epoch 399: Train Loss:0.6839, Macro_F1: 0.5817, AUC_score: 0.5654\n",
      "Epoch 00418: reducing learning rate of group 0 to 4.0000e-04.\n",
      "Epoch 449: Train Loss:0.6792, Macro_F1: 0.6050, AUC_score: 0.5691\n",
      "Epoch 499: Train Loss:0.6669, Macro_F1: 0.5987, AUC_score: 0.5692\n",
      "Epoch 549: Train Loss:0.6670, Macro_F1: 0.6114, AUC_score: 0.5704\n",
      "Epoch 599: Train Loss:0.6701, Macro_F1: 0.5817, AUC_score: 0.5802\n",
      "Epoch 00605: reducing learning rate of group 0 to 8.0000e-05.\n",
      "Epoch 649: Train Loss:0.6699, Macro_F1: 0.6049, AUC_score: 0.5805\n",
      "Epoch 699: Train Loss:0.6593, Macro_F1: 0.6049, AUC_score: 0.5794\n",
      "Epoch 749: Train Loss:0.6594, Macro_F1: 0.6112, AUC_score: 0.5816\n",
      "Epoch 799: Train Loss:0.6786, Macro_F1: 0.5923, AUC_score: 0.5822\n",
      "Epoch 00844: reducing learning rate of group 0 to 1.6000e-05.\n",
      "Epoch 849: Train Loss:0.6687, Macro_F1: 0.6147, AUC_score: 0.5831\n",
      "Epoch 899: Train Loss:0.6702, Macro_F1: 0.6111, AUC_score: 0.5839\n",
      "Epoch 00947: reducing learning rate of group 0 to 3.2000e-06.\n",
      "Epoch 949: Train Loss:0.6730, Macro_F1: 0.6094, AUC_score: 0.5839\n",
      "Epoch 999: Train Loss:0.6688, Macro_F1: 0.6111, AUC_score: 0.5843\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model_scheduler(model, data.x, data.y, data.edge_index, optimizer, loss_fn, scheduler, train_mask)\n",
    "    test_f1, test_auc = evaluate_model(model, data.x, data.y, data.edge_index, test_mask)\n",
    "    \n",
    "    if (epoch + 1) % 50 == 0: \n",
    "        print(f'Epoch {epoch}: Train Loss:{train_loss:.4f}, Macro_F1: {test_f1:.4f}, AUC_score: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4a808-5396-463b-99a1-0eb48b519c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c00c7-6948-489c-8611-a191493d3f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
