{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c3c4cf-260d-4d55-b9bd-c8e0d3a835dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94323/1133472201.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/tmp/ipykernel_94323/1133472201.py:7: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv('GNN/protein_interactions.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      protein  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
      "0         FES  0.339602 -0.030744 -0.901381  0.100888  0.886443  0.383596   \n",
      "1      HADHA  -0.131799 -0.025745 -0.677301 -0.053545  0.971046  0.180315   \n",
      "2      SLC7A7  0.385693 -0.070692 -0.847796 -0.022054  0.959772  0.085487   \n",
      "3        LCK   0.650428  0.014479 -0.866163  0.053508  0.951529  0.269402   \n",
      "4       HSPA2  0.322262  0.017484 -0.849302  0.046401  0.920429  0.463832   \n",
      "...       ...       ...       ...       ...       ...       ...       ...   \n",
      "14445   BPY2C -0.840158 -0.042814 -0.853394 -0.049438  0.943925  0.104337   \n",
      "14446    CLPS -0.270716 -0.036871 -0.915350 -0.013635  0.972046  0.016017   \n",
      "14447    DNER  0.228932 -0.033579 -0.907262  0.010446  0.961684  0.524211   \n",
      "14448    SOX7  0.140491  0.033339 -0.806014 -0.072016  0.938781  0.339959   \n",
      "14449  CXCL14 -0.570266 -0.011502 -0.741149 -0.096209  0.967244  0.426519   \n",
      "\n",
      "       feature7  feature8  feature9  ...  feature759  feature760  feature761  \\\n",
      "0     -0.192082 -0.032063 -0.154869  ...   -0.549204   -0.856123    0.714672   \n",
      "1     -0.028189 -0.077389 -0.095152  ...    0.927885   -0.817812    0.809631   \n",
      "2      0.076455 -0.003006 -0.032268  ...    0.941094   -0.912443    0.789828   \n",
      "3     -0.214788  0.045179 -0.506429  ...   -0.576739   -0.969558    0.916549   \n",
      "4     -0.050414 -0.033398  0.387791  ...    0.387301   -0.860696    0.678607   \n",
      "...         ...       ...       ...  ...         ...         ...         ...   \n",
      "14445 -0.132297 -0.000937 -0.709405  ...    0.923731   -0.709760    0.656196   \n",
      "14446 -0.018190 -0.008408  0.548612  ...    0.946926   -0.739839    0.755471   \n",
      "14447 -0.214318  0.039835  0.433141  ...    0.806205   -0.857853    0.223238   \n",
      "14448 -0.045201 -0.004075 -0.169557  ...    0.756285   -0.889968    0.837899   \n",
      "14449 -0.138793  0.028511 -0.785310  ...    0.979686   -0.660164    0.784033   \n",
      "\n",
      "       feature762  feature763  feature764  feature765  feature766  feature767  \\\n",
      "0       -0.046649   -0.894424   -0.001815    0.739485    0.015581   -0.023863   \n",
      "1       -0.005827   -0.848839    0.024516    0.526404   -0.039926   -0.102787   \n",
      "2        0.046979   -0.715636    0.085842    0.150494    0.025392   -0.066035   \n",
      "3       -0.080332   -0.927649   -0.047398    0.741663   -0.000096   -0.096318   \n",
      "4       -0.060695   -0.945793    0.040472    0.831079   -0.001711   -0.079842   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "14445   -0.029016   -0.879421    0.133864   -0.558606   -0.035379   -0.122373   \n",
      "14446    0.006047   -0.488539    0.009771   -0.261908   -0.048952   -0.062768   \n",
      "14447   -0.078767   -0.973104    0.026339    0.918282   -0.041604   -0.039557   \n",
      "14448   -0.030372   -0.969834   -0.054169    0.099373    0.018777   -0.166461   \n",
      "14449    0.043913   -0.958544    0.016069   -0.345766   -0.004606    0.074345   \n",
      "\n",
      "       feature768  \n",
      "0       -0.022002  \n",
      "1       -0.026980  \n",
      "2       -0.028283  \n",
      "3       -0.056501  \n",
      "4       -0.011189  \n",
      "...           ...  \n",
      "14445   -0.030907  \n",
      "14446    0.019626  \n",
      "14447   -0.014415  \n",
      "14448   -0.062177  \n",
      "14449   -0.093482  \n",
      "\n",
      "[14450 rows x 769 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "edges_df = pd.read_csv('GNN/protein_interactions.csv')\n",
    "\n",
    "col_name = ['protein']\n",
    "for i in range(1,769):\n",
    "  col_name.append('feature'+str(i))\n",
    "features_df = pd.read_csv('GNN/gene_embedding_GeneLLM_2.csv', header=None, names=col_name)\n",
    "\n",
    "print(features_df)\n",
    "labels_df = pd.read_csv('GNN/solubility.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10c7b24-0233-403e-a160-690cf42ee40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Gene name Solubility  Label  Word_Count Count_Category\n",
      "0        ERAP2   Membrane      0         117     High Count\n",
      "1     ADAMTSL5    Soluble      1          28      Low Count\n",
      "2      TBC1D30   Membrane      0          55     High Count\n",
      "3       KCNK18   Membrane      0         184     High Count\n",
      "4         NDNF    Soluble      1         129     High Count\n",
      "...        ...        ...    ...         ...            ...\n",
      "1374   TRABD2B   Membrane      0          96     High Count\n",
      "1375      RPS9    Soluble      1         205     High Count\n",
      "1376  SLC22A16   Membrane      0          93     High Count\n",
      "1377      FBN3    Soluble      1          90     High Count\n",
      "1378      BDH2    Soluble      1         102     High Count\n",
      "\n",
      "[1379 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94323/3707133632.py:2: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges_df['combined_score'][7] = 594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         protein1  protein2 combined_score\n",
      "0            ARF5   RALGPS2            173\n",
      "1            ARF5     FHDC1            154\n",
      "2            ARF5  ATP6V1E1            151\n",
      "3            ARF5     CYTH2            471\n",
      "4            ARF5      PSD3            201\n",
      "...           ...       ...            ...\n",
      "13715123     LDB1    SAMD14            260\n",
      "13715124     LDB1     KDM6B            161\n",
      "13715125     LDB1      WWP2            229\n",
      "13715126     LDB1    VPS33B            152\n",
      "13715127     LDB1     NDST2            440\n",
      "\n",
      "[13067419 rows x 3 columns]\n",
      "         protein1  protein2 combined_score\n",
      "0            ARF5   RALGPS2            173\n",
      "1            ARF5     FHDC1            154\n",
      "2            ARF5  ATP6V1E1            151\n",
      "3            ARF5     CYTH2            471\n",
      "4            ARF5      PSD3            201\n",
      "...           ...       ...            ...\n",
      "13715123     LDB1    SAMD14            260\n",
      "13715124     LDB1     KDM6B            161\n",
      "13715125     LDB1      WWP2            229\n",
      "13715126     LDB1    VPS33B            152\n",
      "13715127     LDB1     NDST2            440\n",
      "\n",
      "[13067419 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(labels_df)\n",
    "edges_df['combined_score'][7] = 594\n",
    "edges_df_cleaned = edges_df.dropna()\n",
    "print(edges_df_cleaned)\n",
    "edges_df_cleaned = edges_df.dropna()\n",
    "print(edges_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf28a98-d763-437a-b754-18a6dc79f7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14450\n",
      "18838\n"
     ]
    }
   ],
   "source": [
    "node_id_f = [node_id for node_id in features_df['protein']]\n",
    "node_id_e1 = [node_id for node_id in edges_df_cleaned['protein1']]\n",
    "node_id_e2 = [node_id for node_id in edges_df_cleaned['protein2']]\n",
    "node_id_e = list(set(node_id_e1 + node_id_e2))\n",
    "print(len(node_id_f))\n",
    "print(len(node_id_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f868118a-1a30-47b8-a060-598003b2c552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>Label</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Count_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERAP2</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>Low Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDNF</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>RPS9</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>FBN3</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>BDH2</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>High Count</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       protein Solubility  Label  Word_Count Count_Category\n",
       "0        ERAP2   Membrane      0         117     High Count\n",
       "1     ADAMTSL5    Soluble      1          28      Low Count\n",
       "2      TBC1D30   Membrane      0          55     High Count\n",
       "3       KCNK18   Membrane      0         184     High Count\n",
       "4         NDNF    Soluble      1         129     High Count\n",
       "...        ...        ...    ...         ...            ...\n",
       "1374   TRABD2B   Membrane      0          96     High Count\n",
       "1375      RPS9    Soluble      1         205     High Count\n",
       "1376  SLC22A16   Membrane      0          93     High Count\n",
       "1377      FBN3    Soluble      1          90     High Count\n",
       "1378      BDH2    Soluble      1         102     High Count\n",
       "\n",
       "[1379 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.rename(columns={'Gene name': 'protein'}, inplace=True)\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c840d878-942c-49f2-ab14-5ad7fa753f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_in_features = set(features_df['protein'])\n",
    "filtered_edges_df = edges_df_cleaned[\n",
    "    edges_df_cleaned['protein1'].isin(nodes_in_features) & edges_df_cleaned['protein2'].isin(nodes_in_features)\n",
    "]\n",
    "# 过滤特征数据集，保留共同节点的特征\n",
    "filtered_features_df = features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8aa50f7-71d9-455c-ac5d-fbee744f3f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High Count' 'Low Count']\n",
      "       protein Solubility  Label  Word_Count  Count_Category\n",
      "0        ERAP2   Membrane      0         117               0\n",
      "1     ADAMTSL5    Soluble      1          28               1\n",
      "2      TBC1D30   Membrane      0          55               0\n",
      "3       KCNK18   Membrane      0         184               0\n",
      "4         NDNF    Soluble      1         129               0\n",
      "...        ...        ...    ...         ...             ...\n",
      "1374   TRABD2B   Membrane      0          96               0\n",
      "1375      RPS9    Soluble      1         205               0\n",
      "1376  SLC22A16   Membrane      0          93               0\n",
      "1377      FBN3    Soluble      1          90               0\n",
      "1378      BDH2    Soluble      1         102               0\n",
      "\n",
      "[1379 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 将第二列中的两种字符映射为0和1\n",
    "unique_values = labels_df['Count_Category'].unique()\n",
    "print(unique_values)\n",
    "mapping = {unique_values[0]: 0, unique_values[1]: 1}\n",
    "\n",
    "labels_df['Count_Category'] = labels_df['Count_Category'].map(mapping)\n",
    "# 显示更新后的DataFrame\n",
    "print(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a357a393-7339-4d07-a40c-c16064efbdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94323/744925070.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_edges_df['combined_score'] = pd.to_numeric(filtered_edges_df['combined_score'], errors='coerce', downcast='float')\n"
     ]
    }
   ],
   "source": [
    "node_id_to_index = {node_id: i for i, node_id in enumerate(filtered_features_df['protein'])}\n",
    "# 确保edge_index是按照这个新的索引顺序排列的\n",
    "source_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['protein1']]\n",
    "target_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['protein2']]\n",
    "edge_index = torch.tensor([source_indices, target_indices], dtype=torch.long)\n",
    "filtered_edges_df['combined_score'] = pd.to_numeric(filtered_edges_df['combined_score'], errors='coerce', downcast='float')\n",
    "edge_weight = torch.tensor(filtered_edges_df['combined_score'].values, dtype=torch.float)\n",
    "\n",
    "# 重排特征矩阵以匹配edge_index的顺序\n",
    "features = filtered_features_df.iloc[:, 1:].values\n",
    "#features = features[[node_id_to_index[node_id] for node_id in filtered_features_df['protein']], :]\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "features_tensor = torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ee766f-766e-4500-b0f9-a11044fb1512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "1379\n",
      "14450\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_df))\n",
    "nodes_in_labels = set(labels_df['protein'])\n",
    "nodes_in_filter_features = set(filtered_features_df['protein'])\n",
    "common_nodes_labels = nodes_in_labels.intersection(nodes_in_filter_features)\n",
    "\n",
    "# 过滤\n",
    "filtered_labels_df = labels_df[labels_df['protein'].isin(common_nodes_labels)].reset_index(drop=True)\n",
    "print(len(filtered_labels_df))\n",
    "print(len(features_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0640149b-ed6c-4350-b8c7-5bbabbb483e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 81, 93, 94, 100, 116, 129, 142, 148, 149, 157, 167, 170, 202, 228, 236, 241, 243, 255, 258, 276, 281, 287, 294, 305, 319, 321, 334, 340, 369, 373, 375, 383, 384, 399, 402, 418, 447, 455, 474, 483, 484, 490, 498, 511, 518, 526, 558, 569, 585, 586, 587, 593, 594, 595, 596, 599, 615, 641, 653, 654, 664, 682, 736, 754, 762, 764, 773, 777, 781, 833, 852, 894, 895, 899, 915, 917, 938, 944, 957, 982, 983, 997, 1003, 1019, 1040, 1047, 1053, 1062, 1064, 1065, 1067, 1074, 1075, 1078, 1079, 1105, 1108, 1115, 1116, 1120, 1124, 1131, 1136, 1137, 1143, 1157, 1170, 1173, 1183, 1195, 1196, 1197, 1215, 1235, 1236, 1237, 1243, 1256, 1261, 1262, 1273, 1274, 1277, 1311, 1315, 1327, 1333, 1347, 1363, 1371, 1377, 1378, 1383, 1392, 1397, 1426, 1427, 1431, 1435, 1444, 1445, 1469, 1470, 1475, 1484, 1489, 1492, 1493, 1521, 1527, 1540, 1548, 1559, 1575, 1593, 1606, 1609, 1614, 1617, 1619, 1637, 1638, 1645, 1674, 1681, 1710, 1720, 1733, 1736, 1737, 1759, 1776, 1795, 1807, 1823, 1833, 1834, 1844, 1848, 1849, 1852, 1854, 1882, 1893, 1895, 1898, 1914, 1917, 1923, 1927, 1960, 1970, 1972, 1978, 1986, 1995, 2015, 2016, 2022, 2031, 2046, 2048, 2071, 2096, 2097, 2099, 2101, 2104, 2109, 2112, 2115, 2117, 2119, 2140, 2151, 2154, 2166, 2188, 2196, 2209, 2214, 2227, 2231, 2238, 2250, 2256, 2265, 2273, 2274, 2277, 2281, 2283, 2284, 2286, 2292, 2293, 2302, 2308, 2316, 2326, 2337, 2353, 2354, 2358, 2362, 2364, 2365, 2370, 2372, 2400, 2417, 2419, 2421, 2422, 2424, 2427, 2455, 2465, 2476, 2481, 2489, 2496, 2505, 2532, 2533, 2535, 2540, 2551, 2556, 2589, 2620, 2625, 2630, 2634, 2660, 2672, 2676, 2686, 2701, 2705, 2708, 2716, 2730, 2738, 2767, 2770, 2785, 2788, 2802, 2804, 2819, 2823, 2827, 2836, 2842, 2862, 2871, 2879, 2888, 2896, 2903, 2907, 2915, 2927, 2928, 2929, 2937, 2950, 2957, 2958, 2960, 2982, 2986, 2995, 3000, 3013, 3014, 3021, 3024, 3027, 3037, 3043, 3044, 3054, 3057, 3064, 3084, 3092, 3099, 3117, 3123, 3147, 3150, 3159, 3180, 3186, 3217, 3240, 3244, 3255, 3268, 3272, 3285, 3291, 3305, 3319, 3325, 3326, 3327, 3330, 3353, 3356, 3382, 3389, 3393, 3408, 3410, 3417, 3433, 3454, 3456, 3465, 3486, 3502, 3511, 3519, 3530, 3535, 3536, 3538, 3543, 3584, 3615, 3619, 3620, 3630, 3647, 3663, 3680, 3684, 3692, 3706, 3707, 3715, 3727, 3747, 3751, 3752, 3754, 3774, 3779, 3781, 3783, 3785, 3786, 3792, 3797, 3802, 3810, 3829, 3833, 3839, 3850, 3882, 3884, 3886, 3902, 3917, 3921, 3923, 3929, 3943, 3949, 3959, 3960, 3968, 3969, 3977, 3985, 3990, 3991, 3992, 4019, 4025, 4034, 4040, 4048, 4049, 4071, 4102, 4120, 4133, 4159, 4165, 4166, 4169, 4178, 4184, 4185, 4197, 4209, 4225, 4232, 4239, 4249, 4251, 4258, 4288, 4323, 4328, 4332, 4333, 4343, 4351, 4360, 4361, 4365, 4375, 4376, 4387, 4417, 4431, 4433, 4438, 4439, 4440, 4464, 4465, 4484, 4485, 4495, 4500, 4507, 4513, 4520, 4524, 4526, 4539, 4545, 4558, 4560, 4565, 4572, 4607, 4616, 4630, 4637, 4653, 4656, 4668, 4676, 4711, 4712, 4716, 4721, 4751, 4760, 4776, 4780, 4783, 4792, 4795, 4796, 4800, 4804, 4806, 4815, 4833, 4836, 4840, 4853, 4882, 4888, 4897, 4913, 4915, 4926, 4930, 4935, 4961, 4963, 4995, 4999, 5006, 5013, 5020, 5041, 5061, 5072, 5077, 5079, 5083, 5085, 5124, 5139, 5144, 5146, 5151, 5154, 5167, 5170, 5173, 5178, 5192, 5209, 5216, 5218, 5226, 5228, 5233, 5242, 5243, 5253, 5264, 5271, 5278, 5280, 5298, 5306, 5312, 5327, 5351, 5379, 5383, 5396, 5399, 5405, 5410, 5418, 5437, 5486, 5488, 5506, 5510, 5512, 5513, 5522, 5555, 5556, 5566, 5569, 5570, 5575, 5582, 5586, 5589, 5593, 5628, 5634, 5635, 5644, 5670, 5674, 5687, 5693, 5702, 5703, 5710, 5713, 5721, 5736, 5738, 5784, 5785, 5787, 5792, 5793, 5820, 5823, 5866, 5884, 5890, 5898, 5899, 5900, 5902, 5913, 5943, 5954, 5958, 5963, 5985, 5991, 5992, 6006, 6011, 6038, 6043, 6057, 6058, 6064, 6066, 6078, 6081, 6094, 6099, 6101, 6112, 6119, 6120, 6127, 6128, 6131, 6134, 6136, 6168, 6177, 6179, 6196, 6203, 6211, 6223, 6226, 6227, 6239, 6246, 6278, 6301, 6302, 6314, 6319, 6328, 6343, 6377, 6389, 6416, 6426, 6427, 6428, 6436, 6438, 6448, 6460, 6494, 6514, 6516, 6517, 6518, 6527, 6528, 6549, 6556, 6559, 6562, 6567, 6569, 6579, 6583, 6593, 6595, 6606, 6607, 6612, 6623, 6628, 6630, 6639, 6667, 6679, 6681, 6699, 6702, 6703, 6714, 6717, 6728, 6744, 6772, 6774, 6782, 6785, 6792, 6804, 6815, 6819, 6823, 6832, 6844, 6850, 6859, 6865, 6871, 6884, 6885, 6886, 6943, 6947, 6963, 6995, 7000, 7017, 7018, 7019, 7026, 7040, 7047, 7049, 7065, 7067, 7073, 7074, 7081, 7083, 7089, 7093, 7108, 7116, 7125, 7130, 7139, 7151, 7152, 7153, 7157, 7170, 7185, 7189, 7192, 7201, 7202, 7203, 7221, 7252, 7266, 7278, 7280, 7281, 7286, 7296, 7300, 7312, 7313, 7341, 7349, 7357, 7365, 7375, 7377, 7387, 7389, 7390, 7412, 7415, 7420, 7427, 7433, 7440, 7449, 7456, 7465, 7469, 7481, 7510, 7520, 7527, 7528, 7549, 7561, 7563, 7564, 7573, 7590, 7591, 7599, 7609, 7610, 7631, 7634, 7640, 7645, 7653, 7654, 7665, 7688, 7692, 7705, 7715, 7721, 7755, 7760, 7769, 7782, 7783, 7793, 7839, 7865, 7889, 7891, 7892, 7921, 7930, 7956, 7958, 8012, 8013, 8031, 8041, 8046, 8060, 8066, 8073, 8075, 8077, 8078, 8124, 8139, 8156, 8175, 8189, 8196, 8204, 8212, 8215, 8225, 8226, 8228, 8229, 8231, 8234, 8243, 8250, 8262, 8266, 8272, 8285, 8290, 8303, 8305, 8323, 8327, 8329, 8339, 8343, 8348, 8349, 8350, 8351, 8356, 8357, 8360, 8366, 8383, 8386, 8389, 8405, 8413, 8419, 8441, 8447, 8451, 8454, 8467, 8480, 8491, 8492, 8497, 8517, 8519, 8535, 8554, 8557, 8560, 8567, 8568, 8576, 8592, 8595, 8600, 8608, 8631, 8632, 8633, 8641, 8645, 8647, 8653, 8672, 8683, 8691, 8716, 8720, 8727, 8733, 8741, 8746, 8748, 8749, 8786, 8808, 8814, 8815, 8818, 8820, 8826, 8828, 8865, 8903, 8927, 8931, 8942, 8946, 8991, 8998, 9013, 9026, 9027, 9056, 9066, 9085, 9097, 9098, 9115, 9126, 9134, 9135, 9144, 9148, 9165, 9189, 9190, 9225, 9231, 9246, 9263, 9293, 9301, 9302, 9323, 9325, 9364, 9385, 9410, 9416, 9423, 9431, 9435, 9437, 9457, 9500, 9512, 9514, 9517, 9535, 9547, 9552, 9561, 9573, 9589, 9607, 9627, 9638, 9639, 9659, 9682, 9708, 9757, 9772, 9776, 9784, 9800, 9809, 9822, 9823, 9828, 9836, 9852, 9853, 9862, 9875, 9885, 9900, 9908, 9910, 9926, 9937, 9978, 10000, 10010, 10023, 10031, 10038, 10045, 10046, 10053, 10060, 10063, 10075, 10090, 10094, 10119, 10125, 10138, 10146, 10147, 10151, 10158, 10159, 10168, 10172, 10183, 10201, 10217, 10246, 10298, 10300, 10309, 10321, 10323, 10325, 10327, 10364, 10372, 10379, 10390, 10409, 10410, 10411, 10418, 10424, 10432, 10435, 10436, 10443, 10452, 10459, 10479, 10483, 10485, 10500, 10502, 10527, 10534, 10536, 10542, 10552, 10561, 10580, 10581, 10607, 10619, 10622, 10623, 10629, 10655, 10666, 10685, 10686, 10695, 10697, 10699, 10700, 10701, 10705, 10708, 10730, 10732, 10751, 10754, 10764, 10765, 10776, 10779, 10789, 10794, 10825, 10828, 10862, 10877, 10887, 10890, 10905, 10917, 10926, 10934, 10951, 10988, 11000, 11002, 11022, 11028, 11033, 11035, 11040, 11050, 11089, 11108, 11109, 11125, 11140, 11142, 11150, 11164, 11175, 11178, 11184, 11187, 11192, 11210, 11222, 11247, 11248, 11273, 11277, 11278, 11286, 11289, 11296, 11307, 11321, 11324, 11340, 11343, 11345, 11362, 11406, 11407, 11410, 11418, 11428, 11458, 11482, 11492, 11497, 11523, 11533, 11538, 11542, 11548, 11549, 11562, 11572, 11583, 11601, 11609, 11634, 11638, 11655, 11657, 11658, 11676, 11688, 11707, 11711, 11734, 11746, 11749, 11752, 11758, 11774, 11803, 11805, 11810, 11820, 11844, 11887, 11928, 11938, 11951, 11958, 11967, 11984, 11987, 12071, 12080, 12102, 12103, 12107, 12111, 12116, 12124, 12130, 12142, 12151, 12154, 12169, 12174, 12193, 12194, 12199, 12205, 12262, 12271, 12272, 12284, 12289, 12296, 12302, 12304, 12323, 12345, 12348, 12358, 12373, 12386, 12429, 12432, 12457, 12470, 12487, 12488, 12511, 12517, 12578, 12579, 12587, 12593, 12666, 12667, 12684, 12705, 12706, 12760, 12776, 12784, 12805, 12819, 12821, 12848, 12864, 12873, 12889, 12918, 12954, 12955, 12956, 12958, 12959, 12974, 13001, 13003, 13017, 13022, 13042, 13045, 13049, 13078, 13083, 13084, 13088, 13090, 13120, 13130, 13138, 13164, 13165, 13181, 13186, 13192, 13206, 13214, 13243, 13251, 13266, 13292, 13295, 13305, 13314, 13321, 13334, 13394, 13409, 13422, 13443, 13447, 13469, 13502, 13512, 13536, 13559, 13566, 13567, 13571, 13580, 13582, 13586, 13594, 13657, 13662, 13666, 13672, 13673, 13685, 13724, 13727, 13741, 13760, 13779, 13826, 13831, 13838, 13847, 13855, 13858, 13862, 13871, 13872, 13874, 13882, 13892, 13898, 13901, 13906, 13924, 13931, 13936, 13943, 13951, 13965, 13978, 13984, 14012, 14015, 14024, 14036, 14052, 14090, 14117, 14146, 14151, 14162, 14214, 14234, 14240, 14241, 14263, 14268, 14279, 14281, 14288, 14293, 14315, 14317, 14318, 14324, 14325, 14398, 14407, 14426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94323/1340105613.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "label_indices = [node_id_to_index[node_id] for node_id in filtered_labels_df['protein']]\n",
    "print(label_indices)\n",
    "num_nodes = len(features_tensor)\n",
    "labels = torch.full((num_nodes,), -1, dtype=torch.long)\n",
    "for i, index in enumerate(filtered_labels_df['Label']):\n",
    "    labels[label_indices[i]] = index\n",
    "\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56e368d9-0544-4054-9e3e-cd7638fcb3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 93, 94, 100, 116, 129, 142, 148, 157, 167, 228, 236, 241, 255, 276, 287, 294, 321, 334, 340, 369, 373, 375, 383, 384, 399, 402, 418, 447, 474, 483, 490, 498, 511, 518, 526, 558, 569, 586, 587, 593, 594, 595, 596, 599, 615, 641, 654, 664, 682, 736, 754, 764, 777, 833, 852, 894, 895, 899, 915, 917, 938, 944, 957, 982, 983, 997, 1003, 1019, 1040, 1053, 1062, 1064, 1065, 1067, 1074, 1075, 1078, 1079, 1105, 1108, 1115, 1116, 1120, 1124, 1131, 1136, 1137, 1143, 1157, 1170, 1173, 1183, 1195, 1196, 1197, 1215, 1235, 1236, 1237, 1243, 1256, 1261, 1273, 1274, 1277, 1311, 1315, 1327, 1333, 1347, 1363, 1377, 1378, 1392, 1397, 1427, 1444, 1445, 1469, 1470, 1475, 1484, 1489, 1492, 1493, 1521, 1548, 1559, 1575, 1593, 1609, 1614, 1617, 1619, 1637, 1638, 1674, 1681, 1720, 1733, 1736, 1737, 1759, 1776, 1795, 1807, 1833, 1834, 1844, 1849, 1852, 1854, 1882, 1893, 1895, 1898, 1914, 1917, 1923, 1960, 1970, 1972, 1978, 1986, 1995, 2015, 2031, 2046, 2048, 2071, 2096, 2097, 2101, 2109, 2115, 2117, 2140, 2151, 2154, 2166, 2188, 2209, 2214, 2227, 2231, 2238, 2250, 2256, 2265, 2273, 2281, 2284, 2286, 2292, 2293, 2302, 2308, 2326, 2337, 2353, 2354, 2362, 2364, 2365, 2372, 2400, 2417, 2419, 2421, 2422, 2424, 2427, 2455, 2465, 2476, 2481, 2489, 2496, 2505, 2532, 2533, 2535, 2540, 2551, 2556, 2589, 2620, 2630, 2634, 2660, 2672, 2676, 2686, 2701, 2708, 2730, 2738, 2767, 2770, 2785, 2788, 2802, 2804, 2819, 2823, 2827, 2842, 2871, 2879, 2888, 2896, 2903, 2907, 2915, 2927, 2928, 2937, 2957, 2958, 2960, 2982, 2986, 3000, 3013, 3014, 3027, 3037, 3044, 3054, 3057, 3064, 3084, 3092, 3099, 3117, 3123, 3147, 3150, 3180, 3186, 3217, 3240, 3244, 3255, 3268, 3272, 3285, 3291, 3319, 3325, 3326, 3330, 3353, 3382, 3393, 3408, 3410, 3417, 3433, 3454, 3456, 3465, 3486, 3502, 3511, 3519, 3530, 3535, 3538, 3543, 3615, 3630, 3647, 3663, 3680, 3706, 3707, 3715, 3727, 3747, 3754, 3774, 3779, 3781, 3783, 3785, 3786, 3792, 3797, 3802, 3810, 3829, 3833, 3839, 3882, 3884, 3902, 3917, 3921, 3923, 3929, 3943, 3949, 3959, 3960, 3968, 3969, 3977, 3985, 3990, 3991, 3992, 4019, 4025, 4034, 4040, 4048, 4049, 4102, 4120, 4133, 4159, 4165, 4166, 4169, 4178, 4184, 4185, 4197, 4209, 4225, 4232, 4239, 4249, 4251, 4258, 4288, 4323, 4328, 4332, 4333, 4343, 4351, 4360, 4365, 4375, 4376, 4387, 4417, 4431, 4433, 4438, 4439, 4440, 4464, 4465, 4484, 4485, 4495, 4500, 4507, 4520, 4524, 4526, 4545, 4558, 4560, 4565, 4572, 4607, 4616, 4630, 4637, 4653, 4656, 4668, 4676, 4711, 4716, 4721, 4751, 4760, 4776, 4780, 4783, 4792, 4795, 4800, 4804, 4806, 4833, 4836, 4840, 4853, 4882, 4888, 4897, 4913, 4915, 4926, 4930, 4935, 4961, 4963, 4995, 5006, 5013, 5020, 5041, 5061, 5072, 5077, 5079, 5083, 5124, 5139, 5144, 5146, 5151, 5154, 5167, 5170, 5178, 5192, 5209, 5216, 5218, 5226, 5228, 5233, 5242, 5243, 5253, 5264, 5271, 5278, 5280, 5298, 5306, 5312, 5351, 5379, 5396, 5399, 5405, 5410, 5418, 5437, 5486, 5488, 5506, 5510, 5512, 5513, 5522, 5556, 5566, 5569, 5570, 5575, 5582, 5586, 5589, 5593, 5628, 5635, 5644, 5670, 5674, 5687, 5693, 5702, 5703, 5713, 5721, 5736, 5738, 5784, 5785, 5787, 5792, 5820, 5823, 5884, 5890, 5898, 5899, 5902, 5943, 5954, 5958, 5963, 5985, 5991, 5992, 6006, 6011, 6038, 6043, 6057, 6058, 6064, 6078, 6081, 6094, 6101, 6112, 6119, 6120, 6127, 6128, 6131, 6134, 6136, 6177, 6179, 6196, 6203, 6211, 6223, 6227, 6239, 6246, 6301, 6302, 6314, 6319, 6328, 6343, 6377, 6389, 6416, 6426, 6427, 6428, 6436, 6438, 6448, 6460, 6494, 6514, 6517, 6518, 6527, 6528, 6549, 6559, 6562, 6567, 6579, 6583, 6595, 6606, 6607, 6612, 6623, 6628, 6630, 6639, 6667, 6679, 6681, 6699, 6702, 6703, 6714, 6717, 6728, 6744, 6772, 6774, 6782, 6785, 6792, 6804, 6815, 6819, 6823, 6832, 6844, 6850, 6859, 6865, 6871, 6884, 6885, 6886, 6943, 6947, 6963, 6995, 7000, 7017, 7018, 7019, 7026, 7040, 7047, 7049, 7065, 7067, 7073, 7074, 7081, 7083, 7089, 7093, 7108, 7116, 7125, 7130, 7139, 7151, 7152, 7153, 7157, 7170, 7185, 7189, 7192, 7201, 7202, 7203, 7221, 7252, 7266, 7278, 7280, 7281, 7286, 7296, 7300, 7312, 7313, 7341, 7349, 7357, 7375, 7377, 7387, 7389, 7390, 7412, 7415, 7420, 7427, 7433, 7440, 7456, 7465, 7469, 7481, 7510, 7520, 7527, 7528, 7549, 7561, 7563, 7564, 7573, 7590, 7591, 7599, 7609, 7610, 7631, 7634, 7640, 7653, 7654, 7665, 7688, 7692, 7705, 7715, 7721, 7755, 7760, 7769, 7782, 7793, 7839, 7865, 7889, 7891, 7892, 7921, 7930, 7956, 7958, 8013, 8031, 8041, 8046, 8060, 8066, 8073, 8075, 8077, 8078, 8124, 8139, 8156, 8175, 8189, 8196, 8204, 8212, 8215, 8225, 8226, 8228, 8229, 8234, 8243, 8250, 8262, 8266, 8272, 8285, 8290, 8303, 8305, 8323, 8327, 8329, 8339, 8343, 8348, 8350, 8351, 8356, 8357, 8360, 8366, 8383, 8386, 8405, 8413, 8419, 8441, 8447, 8454, 8467, 8491, 8492, 8497, 8517, 8519, 8554, 8557, 8560, 8567, 8568, 8576, 8592, 8595, 8600, 8608, 8631, 8632, 8633, 8641, 8645, 8647, 8653, 8672, 8683, 8691, 8716, 8720, 8727, 8733, 8741, 8746, 8748, 8749, 8786, 8808, 8814, 8815, 8818, 8820, 8826, 8828, 8865, 8927, 8931, 8942, 8946, 8991, 8998, 9013, 9026, 9027, 9056, 9066, 9085, 9097, 9098, 9115, 9126, 9134, 9135, 9144, 9148, 9189, 9190, 9225, 9246, 9263, 9293, 9301, 9302, 9323, 9325, 9364, 9410, 9416, 9423, 9431, 9435, 9437, 9457, 9500, 9512, 9514, 9517, 9535, 9547, 9552, 9561, 9573, 9627, 9638, 9639, 9659, 9682, 9708, 9757, 9776, 9784, 9800, 9809, 9822, 9823, 9828, 9836, 9853, 9862, 9875, 9885, 9908, 9910, 9926, 9937, 9978, 10000, 10010, 10023, 10031, 10045, 10046, 10053, 10060, 10063, 10075, 10090, 10094, 10119, 10125, 10138, 10146, 10147, 10151, 10158, 10159, 10168, 10172, 10183, 10201, 10217, 10246, 10298, 10300, 10309, 10323, 10325, 10327, 10364, 10372, 10379, 10390, 10411, 10418, 10424, 10435, 10436, 10443, 10452, 10459, 10479, 10483, 10485, 10500, 10502, 10527, 10534, 10536, 10542, 10552, 10561, 10580, 10581, 10607, 10619, 10622, 10623, 10655, 10666, 10685, 10686, 10695, 10699, 10700, 10701, 10705, 10730, 10732, 10751, 10764, 10765, 10776, 10779, 10789, 10825, 10828, 10862, 10877, 10887, 10890, 10905, 10917, 10926, 10934, 10951, 10988, 11000, 11002, 11022, 11028, 11033, 11035, 11040, 11050, 11089, 11108, 11109, 11140, 11142, 11150, 11164, 11175, 11178, 11184, 11187, 11192, 11210, 11222, 11247, 11248, 11273, 11277, 11278, 11286, 11289, 11296, 11307, 11321, 11324, 11340, 11343, 11345, 11362, 11406, 11407, 11410, 11418, 11428, 11458, 11482, 11492, 11497, 11523, 11533, 11538, 11542, 11548, 11549, 11562, 11572, 11583, 11601, 11638, 11655, 11657, 11676, 11711, 11734, 11752, 11774, 11803, 11805, 11844, 11928, 11938, 11951, 11958, 11967, 11984, 11987, 12071, 12080, 12102, 12103, 12107, 12111, 12116, 12124, 12130, 12142, 12154, 12169, 12174, 12193, 12194, 12199, 12262, 12289, 12296, 12304, 12323, 12345, 12358, 12373, 12429, 12457, 12470, 12487, 12488, 12511, 12578, 12579, 12587, 12593, 12666, 12667, 12684, 12705, 12706, 12776, 12784, 12805, 12819, 12821, 12864, 12873, 12954, 12955, 12956, 12958, 12959, 12974, 13017, 13022, 13042, 13078, 13084, 13090, 13120, 13130, 13138, 13165, 13181, 13186, 13192, 13206, 13214, 13243, 13251, 13266, 13292, 13295, 13305, 13314, 13321, 13334, 13394, 13409, 13422, 13443, 13447, 13469, 13502, 13512, 13536, 13567, 13571, 13580, 13582, 13586, 13594, 13662, 13672, 13673, 13724, 13727, 13741, 13760, 13779, 13826, 13831, 13838, 13847, 13855, 13858, 13874, 13882, 13892, 13898, 13901, 13906, 13924, 13931, 13943, 13951, 13965, 13984, 14036, 14052, 14090, 14117, 14146, 14214, 14234, 14240, 14241, 14263, 14268, 14279, 14281, 14288, 14293, 14315, 14317, 14318, 14324, 14325, 14398, 14407, 14426]\n",
      "[81, 149, 170, 202, 243, 258, 281, 305, 319, 455, 484, 585, 653, 762, 773, 781, 1047, 1262, 1371, 1383, 1426, 1431, 1435, 1527, 1540, 1606, 1645, 1710, 1823, 1848, 1927, 2016, 2022, 2099, 2104, 2112, 2119, 2196, 2274, 2277, 2283, 2316, 2358, 2370, 2625, 2705, 2716, 2836, 2862, 2929, 2950, 2995, 3021, 3024, 3043, 3159, 3305, 3327, 3356, 3389, 3536, 3584, 3619, 3620, 3684, 3692, 3751, 3752, 3850, 3886, 4071, 4361, 4513, 4539, 4712, 4796, 4815, 4999, 5085, 5173, 5327, 5383, 5555, 5634, 5710, 5793, 5866, 5900, 5913, 6066, 6099, 6168, 6226, 6278, 6516, 6556, 6569, 6593, 7365, 7449, 7645, 7783, 8012, 8231, 8349, 8389, 8451, 8480, 8535, 8903, 9165, 9231, 9385, 9589, 9607, 9772, 9852, 9900, 10038, 10321, 10409, 10410, 10432, 10629, 10697, 10708, 10754, 10794, 11125, 11609, 11634, 11658, 11688, 11707, 11746, 11749, 11758, 11810, 11820, 11887, 12151, 12205, 12271, 12272, 12284, 12302, 12348, 12386, 12432, 12517, 12760, 12848, 12889, 12918, 13001, 13003, 13045, 13049, 13083, 13088, 13164, 13559, 13566, 13657, 13666, 13685, 13862, 13871, 13872, 13936, 13978, 14012, 14015, 14024, 14151, 14162]\n"
     ]
    }
   ],
   "source": [
    "highinfo_indices = [\n",
    "    node_id_to_index[node_id]\n",
    "    for node_id, weight in zip(filtered_labels_df['protein'], filtered_labels_df['Count_Category'])\n",
    "    if weight == 0\n",
    "]\n",
    "print(highinfo_indices)\n",
    "lowinfo_indices = [\n",
    "    node_id_to_index[node_id]\n",
    "    for node_id, weight in zip(filtered_labels_df['protein'], filtered_labels_df['Count_Category'])\n",
    "    if weight == 1\n",
    "]\n",
    "print(lowinfo_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9622bef3-85dc-46bd-8ae5-cafc885c8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "print(len(highinfo_indices))\n",
    "print(len(lowinfo_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cfc9dc2-5598-4abf-8998-6c5d0875e780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([14450, 768]) torch.float32\n",
      "edge_index: torch.Size([2, 9503503]) torch.int64\n",
      "labels: torch.Size([14450]) torch.int64\n",
      "edge_weight: torch.Size([9503503]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "data = Data(x=features_tensor, edge_index=edge_index, y=labels_tensor, edge_attr=edge_weight)\n",
    "\n",
    "print(\"x:\", data.x.shape, data.x.dtype)\n",
    "print(\"edge_index:\", data.edge_index.shape, data.edge_index.dtype)\n",
    "print(\"labels:\", data.y.shape, data.y.dtype)\n",
    "print(\"edge_weight:\", data.edge_attr.shape, data.edge_attr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95434b81-c747-4265-b516-aaaae1771cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 128)\n",
    "        self.conv2 = GCNConv(128, hidden_dim)\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, num_classes)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # 保存初始特征\n",
    "        initial_features = x\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "\n",
    "        # 在这里将初始特征和 GCN 的输出拼接在一起\n",
    "        #x = torch.cat([x, initial_features], dim=1)\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)   #应用 Sigmoid 激活函数进行逻辑回归\n",
    "    def get_embeddings(self, x, edge_index, edge_weight):\n",
    "        initial_features = x\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67370305-c5c4-4276-9e9a-b40f3d6454ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   67,    81,    93,  ..., 14398, 14407, 14426])\n",
      "276\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "Epoch 0: Train Loss:0.6932, F1: 0.5954, AUC_score: 0.5448\n",
      "Epoch 50: Train Loss:0.6437, F1: 0.5878, AUC_score: 0.6567\n",
      "Epoch 100: Train Loss:0.6141, F1: 0.5455, AUC_score: 0.6513\n",
      "Epoch 150: Train Loss:0.5999, F1: 0.5596, AUC_score: 0.6560\n",
      "Epoch 200: Train Loss:0.7162, F1: 0.0331, AUC_score: 0.5668\n",
      "Epoch 250: Train Loss:0.5857, F1: 0.6350, AUC_score: 0.6898\n",
      "Epoch 300: Train Loss:0.5645, F1: 0.5919, AUC_score: 0.6974\n",
      "Epoch 350: Train Loss:0.5737, F1: 0.6717, AUC_score: 0.7347\n",
      "Epoch 400: Train Loss:0.5589, F1: 0.5584, AUC_score: 0.7355\n",
      "Epoch 450: Train Loss:0.5388, F1: 0.5729, AUC_score: 0.7553\n",
      "Epoch 500: Train Loss:0.5659, F1: 0.5871, AUC_score: 0.7807\n",
      "Epoch 550: Train Loss:0.5185, F1: 0.6132, AUC_score: 0.8102\n",
      "Epoch 600: Train Loss:0.4999, F1: 0.7236, AUC_score: 0.8293\n",
      "Epoch 650: Train Loss:0.5101, F1: 0.6509, AUC_score: 0.8359\n",
      "Epoch 700: Train Loss:0.5008, F1: 0.7452, AUC_score: 0.8373\n",
      "Epoch 750: Train Loss:0.4714, F1: 0.7591, AUC_score: 0.8513\n",
      "Epoch 800: Train Loss:0.4852, F1: 0.7280, AUC_score: 0.8553\n",
      "Epoch 850: Train Loss:0.4598, F1: 0.7333, AUC_score: 0.8573\n",
      "Epoch 900: Train Loss:0.4748, F1: 0.7619, AUC_score: 0.8550\n",
      "Epoch 950: Train Loss:0.4668, F1: 0.7681, AUC_score: 0.8641\n",
      "Epoch 1000: Train Loss:0.5087, F1: 0.7593, AUC_score: 0.8527\n",
      "Epoch 1050: Train Loss:0.4518, F1: 0.7529, AUC_score: 0.8636\n",
      "Epoch 1100: Train Loss:0.5150, F1: 0.7556, AUC_score: 0.8653\n",
      "Epoch 1150: Train Loss:0.4358, F1: 0.7439, AUC_score: 0.8659\n",
      "Epoch 1200: Train Loss:0.4472, F1: 0.7446, AUC_score: 0.8691\n",
      "Epoch 1250: Train Loss:0.4246, F1: 0.7552, AUC_score: 0.8701\n",
      "Epoch 1300: Train Loss:0.4535, F1: 0.7606, AUC_score: 0.8684\n",
      "Epoch 1350: Train Loss:0.4518, F1: 0.7577, AUC_score: 0.8679\n",
      "Epoch 1400: Train Loss:0.4721, F1: 0.7387, AUC_score: 0.8671\n",
      "Epoch 01418: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 1450: Train Loss:0.4183, F1: 0.7729, AUC_score: 0.8701\n",
      "Epoch 1500: Train Loss:0.4204, F1: 0.7638, AUC_score: 0.8707\n",
      "Epoch 1550: Train Loss:0.4155, F1: 0.7608, AUC_score: 0.8711\n",
      "Epoch 1600: Train Loss:0.4154, F1: 0.7619, AUC_score: 0.8713\n",
      "Epoch 1650: Train Loss:0.4114, F1: 0.7722, AUC_score: 0.8720\n",
      "Epoch 1700: Train Loss:0.4112, F1: 0.7680, AUC_score: 0.8722\n",
      "Epoch 1750: Train Loss:0.4117, F1: 0.7698, AUC_score: 0.8715\n",
      "Epoch 1800: Train Loss:0.4148, F1: 0.7680, AUC_score: 0.8724\n",
      "Epoch 1850: Train Loss:0.4163, F1: 0.7663, AUC_score: 0.8719\n",
      "Epoch 1900: Train Loss:0.4083, F1: 0.7686, AUC_score: 0.8717\n",
      "Epoch 1950: Train Loss:0.4053, F1: 0.7680, AUC_score: 0.8732\n",
      "Epoch 2000: Train Loss:0.4124, F1: 0.7649, AUC_score: 0.8728\n",
      "Epoch 2050: Train Loss:0.4110, F1: 0.7686, AUC_score: 0.8738\n",
      "Epoch 2100: Train Loss:0.4137, F1: 0.7837, AUC_score: 0.8749\n",
      "Epoch 2150: Train Loss:0.4024, F1: 0.7819, AUC_score: 0.8755\n",
      "Epoch 2200: Train Loss:0.4093, F1: 0.7747, AUC_score: 0.8751\n",
      "Epoch 2250: Train Loss:0.4033, F1: 0.7805, AUC_score: 0.8751\n",
      "Epoch 2300: Train Loss:0.3962, F1: 0.7704, AUC_score: 0.8752\n",
      "Epoch 2350: Train Loss:0.3964, F1: 0.7747, AUC_score: 0.8755\n",
      "Epoch 2400: Train Loss:0.4054, F1: 0.7869, AUC_score: 0.8774\n",
      "Epoch 02442: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 2450: Train Loss:0.3986, F1: 0.7791, AUC_score: 0.8770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "data = data.to(device)\n",
    "# 加载数据\n",
    "features = data.x\n",
    "labels = data.y # 根据你的数据加载函数进行调整\n",
    "\n",
    "original_features = features.clone()\n",
    "\n",
    "# 初始化GNN模型\n",
    "model = GCN(num_features=features.shape[1], hidden_dim=64, num_classes=1).to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=100, verbose=True)\n",
    "\n",
    "label_indices = torch.tensor(label_indices, dtype=torch.long)\n",
    "print(label_indices)\n",
    "# 随机打乱有标签的节点索引\n",
    "labeled_indices = label_indices[torch.randperm(label_indices.size(0))]\n",
    "#print(labeled_indices)\n",
    "labeled_indices = label_indices\n",
    "\n",
    "# 定义训练和测试集的大小\n",
    "num_labeled = labeled_indices.size(0)\n",
    "num_train = int(num_labeled * 0.8)\n",
    "num_test = num_labeled - num_train\n",
    "print(num_test)\n",
    "\n",
    "# 创建训练和测试掩码\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[labeled_indices[:num_train]] = True\n",
    "test_mask[labeled_indices[num_train:num_train+num_test]] = True\n",
    "print(test_mask)\n",
    "\n",
    "def train_model(model, masked_features, labels, edge_index, edge_attr, optimizer, criterion, train_mask):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index, edge_attr)  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], labels[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    return loss.item()\n",
    "\n",
    "def train_model_scheduler(model, masked_features, labels, edge_index, edge_attr, optimizer, criterion, scheduler, train_mask):\n",
    "    model.train()  # 设置模型为训练模\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index, edge_attr).squeeze()  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask].float())  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    scheduler.step(loss)\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, features, labels, edge_index, edge_attr, mask):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        # 获取模型输出，这里假设输出已经是经过sigmoid的概率\n",
    "        probabilities = model(features, edge_index, edge_attr)[mask].squeeze()\n",
    "\n",
    "        # 将概率转换为类别预测，这里使用0.5作为阈值\n",
    "        predicted = (probabilities > 0.5).long()\n",
    "\n",
    "        # 计算准确率\n",
    "        correct = (predicted == labels[mask]).sum().item()\n",
    "        acc = correct / mask.sum().item()\n",
    "\n",
    "        # 计算AUC得分\n",
    "        # 注意：这里直接使用probabilities，因为AUC需要概率值\n",
    "        auc_score = roc_auc_score(labels[mask].cpu().numpy(), probabilities.cpu().numpy())\n",
    "        f1 = f1_score(labels[mask].cpu().numpy(), predicted.cpu().numpy())\n",
    "        return acc, auc_score, f1\n",
    "\n",
    " \n",
    "# 总节点数\n",
    "num_nodes = features.size(0)\n",
    "# 所有节点的索引\n",
    "all_indices = np.arange(num_nodes)\n",
    "\n",
    "# 循环中不断更新的未被选中节点列表\n",
    "remaining_indices = all_indices\n",
    "\n",
    "num_epochs = 2500\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model_scheduler(model, data.x, data.y, data.edge_index, data.edge_attr, optimizer, criterion, scheduler, train_mask)\n",
    "    #train_loss = train_model(model, data.x, data.y, data.edge_index, data.edge_attr, optimizer, criterion, train_mask)\n",
    "    test_acc, test_auc, test_f1 = evaluate_model(model, data.x, data.y, data.edge_index, data.edge_attr, test_mask)\n",
    "    \n",
    "    if epoch % 50 == 0:  # 每10个epoch打印一次信息\n",
    "        print(f'Epoch {epoch}: Train Loss:{train_loss:.4f}, F1: {test_f1:.4f}, AUC_score: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bff5e3b-67bd-4938-a704-412ea7761962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   67,    81,    93,  ..., 14398, 14407, 14426])\n",
      "276\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cpu')\n",
    "data = data.to(device)\n",
    "# 加载数据\n",
    "features = data.x\n",
    "labels = data.y # 根据你的数据加载函数进行调整\n",
    "\n",
    "original_features = features.clone()\n",
    "\n",
    "# 初始化GNN模型\n",
    "model = GCN(num_features=features.shape[1], hidden_dim=64, num_classes=1).to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=100, verbose=True)\n",
    "\n",
    "label_indices = torch.tensor(label_indices, dtype=torch.long)\n",
    "print(label_indices)\n",
    "# 随机打乱有标签的节点索引\n",
    "labeled_indices = label_indices[torch.randperm(label_indices.size(0))]\n",
    "#print(labeled_indices)\n",
    "labeled_indices = label_indices\n",
    "\n",
    "# 定义训练和测试集的大小\n",
    "num_labeled = labeled_indices.size(0)\n",
    "num_train = int(num_labeled * 0.8)\n",
    "num_test = num_labeled - num_train\n",
    "print(num_test)\n",
    "\n",
    "# 创建训练和测试掩码\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[labeled_indices[:num_train]] = True\n",
    "test_mask[labeled_indices[num_train:num_train+num_test]] = True\n",
    "print(test_mask)\n",
    "\n",
    "def train_model(model, masked_features, labels, edge_index, edge_attr, optimizer, criterion, train_mask):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index, edge_attr)  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], labels[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    return loss.item()\n",
    "\n",
    "def train_model_scheduler(model, masked_features, labels, edge_index, edge_attr, optimizer, criterion, scheduler, train_mask):\n",
    "    model.train()  # 设置模型为训练模\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index, edge_attr).squeeze()  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask].float())  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    scheduler.step(loss)\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, features, labels, edge_index, edge_attr, mask):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        # 获取模型输出，这里假设输出已经是经过sigmoid的概率\n",
    "        probabilities = model(features, edge_index, edge_attr)[mask].squeeze()\n",
    "\n",
    "        # 将概率转换为类别预测，这里使用0.5作为阈值\n",
    "        predicted = (probabilities > 0.5).long()\n",
    "\n",
    "        # 计算准确率\n",
    "        correct = (predicted == labels[mask]).sum().item()\n",
    "        acc = correct / mask.sum().item()\n",
    "\n",
    "        # 计算AUC得分\n",
    "        # 注意：这里直接使用probabilities，因为AUC需要概率值\n",
    "        auc_score = roc_auc_score(labels[mask].cpu().numpy(), probabilities.cpu().numpy())\n",
    "        f1 = f1_score(labels[mask].cpu().numpy(), predicted.cpu().numpy())\n",
    "        return acc, auc_score, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9561166-dc55-4428-a6f1-7589af812dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GCN(num_features=features.shape[1], hidden_dim=64, num_classes=1).to(device)\n",
    "model.load_state_dict(torch.load('GCN.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d29267c-568b-4a6a-b941-199e91337e4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_acc, test_auc, test_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AUC_score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 63\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, features, labels, edge_index, edge_attr, mask)\u001b[0m\n\u001b[1;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# 设置模型为评估模式\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# 关闭梯度计算\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# 获取模型输出，这里假设输出已经是经过sigmoid的概率\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# 将概率转换为类别预测，这里使用0.5作为阈值\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     predicted \u001b[38;5;241m=\u001b[39m (probabilities \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "test_acc, test_auc, test_f1 = evaluate_model(model, data.x, data.y, data.edge_index, data.edge_attr, test_mask)\n",
    "print(f'F1: {test_f1:.4f}, AUC_score: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "435ab449-42c8-4a9f-b358-ed37fcc02f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2713, 0.2779, 0.2735,  ..., 0.0000, 0.0000, 0.0379],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.2435],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0256],\n",
       "        ...,\n",
       "        [0.1471, 0.1547, 0.1509,  ..., 0.0000, 0.0000, 0.0664],\n",
       "        [0.2502, 0.2556, 0.2555,  ..., 0.0000, 0.0000, 0.0348],\n",
       "        [0.3536, 0.3572, 0.3565,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.get_embeddings(data.x, data.edge_index, data.edge_attr)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f47d3b6a-4231-4d76-a932-038c22caf59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14450"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd54dc32-c9b3-4e1e-adf5-0584cd750859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27130732, 0.27793735, 0.27353567, ..., 0.        , 0.        ,\n",
       "        0.03792006],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.2435288 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.02556284],\n",
       "       ...,\n",
       "       [0.14714986, 0.15466674, 0.15090339, ..., 0.        , 0.        ,\n",
       "        0.06636678],\n",
       "       [0.2501974 , 0.25563705, 0.2554849 , ..., 0.        , 0.        ,\n",
       "        0.03484946],\n",
       "       [0.3535686 , 0.35717827, 0.35645118, ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3b8708f-d321-4af5-b697-87ac32b69d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(output.detach().numpy(), columns=[f'Feature_{i}' for i in range(output.shape[1])])\n",
    "embeddings_df.insert(0, 'name', filtered_features_df['protein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c44f03c5-cd47-4217-9219-d4683efc297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.to_csv('PPI.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e18707b-ef22-4cb1-8d73-a792e7bdb61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>Label</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Count_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERAP2</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDNF</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>RPS9</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>FBN3</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>BDH2</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name Solubility  Label  Word_Count  Count_Category\n",
       "0        ERAP2   Membrane      0         117               0\n",
       "1     ADAMTSL5    Soluble      1          28               1\n",
       "2      TBC1D30   Membrane      0          55               0\n",
       "3       KCNK18   Membrane      0         184               0\n",
       "4         NDNF    Soluble      1         129               0\n",
       "...        ...        ...    ...         ...             ...\n",
       "1374   TRABD2B   Membrane      0          96               0\n",
       "1375      RPS9    Soluble      1         205               0\n",
       "1376  SLC22A16   Membrane      0          93               0\n",
       "1377      FBN3    Soluble      1          90               0\n",
       "1378      BDH2    Soluble      1         102               0\n",
       "\n",
       "[1379 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60fdef69-17c4-4552-85d6-ee167df15616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_55</th>\n",
       "      <th>Feature_56</th>\n",
       "      <th>Feature_57</th>\n",
       "      <th>Feature_58</th>\n",
       "      <th>Feature_59</th>\n",
       "      <th>Feature_60</th>\n",
       "      <th>Feature_61</th>\n",
       "      <th>Feature_62</th>\n",
       "      <th>Feature_63</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERAP2</td>\n",
       "      <td>0.284831</td>\n",
       "      <td>0.287351</td>\n",
       "      <td>0.289329</td>\n",
       "      <td>0.253635</td>\n",
       "      <td>0.225623</td>\n",
       "      <td>0.184859</td>\n",
       "      <td>0.289319</td>\n",
       "      <td>0.189595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299055</td>\n",
       "      <td>0.221455</td>\n",
       "      <td>0.305924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>0.361459</td>\n",
       "      <td>0.352136</td>\n",
       "      <td>0.358208</td>\n",
       "      <td>0.309579</td>\n",
       "      <td>0.240752</td>\n",
       "      <td>0.204012</td>\n",
       "      <td>0.338186</td>\n",
       "      <td>0.204649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375555</td>\n",
       "      <td>0.271339</td>\n",
       "      <td>0.375699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>0.381606</td>\n",
       "      <td>0.388147</td>\n",
       "      <td>0.379526</td>\n",
       "      <td>0.335721</td>\n",
       "      <td>0.131052</td>\n",
       "      <td>0.104529</td>\n",
       "      <td>0.148468</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390586</td>\n",
       "      <td>0.293074</td>\n",
       "      <td>0.401963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.759943</td>\n",
       "      <td>0.632143</td>\n",
       "      <td>1.044012</td>\n",
       "      <td>0.629058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDNF</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.244775</td>\n",
       "      <td>0.252809</td>\n",
       "      <td>0.218678</td>\n",
       "      <td>0.323325</td>\n",
       "      <td>0.269871</td>\n",
       "      <td>0.434782</td>\n",
       "      <td>0.270781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.260071</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>0.266203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>0.305565</td>\n",
       "      <td>0.293708</td>\n",
       "      <td>0.302368</td>\n",
       "      <td>0.260341</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.267527</td>\n",
       "      <td>0.444895</td>\n",
       "      <td>0.266764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316970</td>\n",
       "      <td>0.228464</td>\n",
       "      <td>0.316689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>RPS9</td>\n",
       "      <td>0.311494</td>\n",
       "      <td>0.330044</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.288819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330282</td>\n",
       "      <td>0.248358</td>\n",
       "      <td>0.330735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.892930</td>\n",
       "      <td>0.740275</td>\n",
       "      <td>1.228003</td>\n",
       "      <td>0.736318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>FBN3</td>\n",
       "      <td>0.432874</td>\n",
       "      <td>0.438728</td>\n",
       "      <td>0.431085</td>\n",
       "      <td>0.380828</td>\n",
       "      <td>0.054895</td>\n",
       "      <td>0.041863</td>\n",
       "      <td>0.053413</td>\n",
       "      <td>0.048202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449401</td>\n",
       "      <td>0.332195</td>\n",
       "      <td>0.455614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>BDH2</td>\n",
       "      <td>0.293795</td>\n",
       "      <td>0.302770</td>\n",
       "      <td>0.297671</td>\n",
       "      <td>0.265449</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.098699</td>\n",
       "      <td>0.144542</td>\n",
       "      <td>0.106678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.310382</td>\n",
       "      <td>0.231282</td>\n",
       "      <td>0.316968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  \\\n",
       "0        ERAP2   0.284831   0.287351   0.289329   0.253635   0.225623   \n",
       "1     ADAMTSL5   0.361459   0.352136   0.358208   0.309579   0.240752   \n",
       "2      TBC1D30   0.381606   0.388147   0.379526   0.335721   0.131052   \n",
       "3       KCNK18   0.000000   0.000000   0.000000   0.000000   0.759943   \n",
       "4         NDNF   0.249400   0.244775   0.252809   0.218678   0.323325   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "1374   TRABD2B   0.305565   0.293708   0.302368   0.260341   0.315700   \n",
       "1375      RPS9   0.311494   0.330044   0.307260   0.288819   0.000000   \n",
       "1376  SLC22A16   0.000000   0.000000   0.000000   0.000000   0.892930   \n",
       "1377      FBN3   0.432874   0.438728   0.431085   0.380828   0.054895   \n",
       "1378      BDH2   0.293795   0.302770   0.297671   0.265449   0.126300   \n",
       "\n",
       "      Feature_5  Feature_6  Feature_7  Feature_8  ...  Feature_55  Feature_56  \\\n",
       "0      0.184859   0.289319   0.189595        0.0  ...    0.253243         0.0   \n",
       "1      0.204012   0.338186   0.204649        0.0  ...    0.319501         0.0   \n",
       "2      0.104529   0.148468   0.110500        0.0  ...    0.332554         0.0   \n",
       "3      0.632143   1.044012   0.629058        0.0  ...    0.000000         0.0   \n",
       "4      0.269871   0.434782   0.270781        0.0  ...    0.222504         0.0   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "1374   0.267527   0.444895   0.266764        0.0  ...    0.270635         0.0   \n",
       "1375   0.000000   0.000000   0.000000        0.0  ...    0.265688         0.0   \n",
       "1376   0.740275   1.228003   0.736318        0.0  ...    0.000000         0.0   \n",
       "1377   0.041863   0.053413   0.048202        0.0  ...    0.379332         0.0   \n",
       "1378   0.098699   0.144542   0.106678        0.0  ...    0.258142         0.0   \n",
       "\n",
       "      Feature_57  Feature_58  Feature_59  Feature_60  Feature_61  Feature_62  \\\n",
       "0            0.0    0.299055    0.221455    0.305924         0.0         0.0   \n",
       "1            0.0    0.375555    0.271339    0.375699         0.0         0.0   \n",
       "2            0.0    0.390586    0.293074    0.401963         0.0         0.0   \n",
       "3            0.0    0.000000    0.000000    0.000000         0.0         0.0   \n",
       "4            0.0    0.260071    0.191385    0.266203         0.0         0.0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1374         0.0    0.316970    0.228464    0.316689         0.0         0.0   \n",
       "1375         0.0    0.330282    0.248358    0.330735         0.0         0.0   \n",
       "1376         0.0    0.000000    0.000000    0.000000         0.0         0.0   \n",
       "1377         0.0    0.449401    0.332195    0.455614         0.0         0.0   \n",
       "1378         0.0    0.310382    0.231282    0.316968         0.0         0.0   \n",
       "\n",
       "      Feature_63  Label  \n",
       "0       0.004109      0  \n",
       "1       0.000000      1  \n",
       "2       0.018417      0  \n",
       "3       0.000000      0  \n",
       "4       0.000000      1  \n",
       "...          ...    ...  \n",
       "1374    0.000000      0  \n",
       "1375    0.218973      1  \n",
       "1376    0.000000      0  \n",
       "1377    0.008581      1  \n",
       "1378    0.087237      1  \n",
       "\n",
       "[1379 rows x 66 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.rename(columns={'protein':'name'}, inplace=True)\n",
    "label_df = labels_df[['name', 'Label']]\n",
    "merged_df = pd.merge(embeddings_df, label_df, on='name', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e1a113c-aef5-4995-826a-156163aa4eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8115942028985508\n",
      "Logistic Regression AUC: 0.8802787162162163\n",
      "Linear Regression Accuracy: 0.782608695652174\n",
      "Linear Regression AUC: 0.8815983952702702\n"
     ]
    }
   ],
   "source": [
    "X = merged_df.drop(columns=['name', 'Label'])\n",
    "y = merged_df['Label']\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 标准化 embeddings\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 降维（可选）\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 拆分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练逻辑回归模型\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 进行预测\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "y_pred_prob_logistic = logistic_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 计算逻辑回归的准确率和AUC\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "auc_logistic = roc_auc_score(y_test, y_pred_prob_logistic)\n",
    "print(f'Logistic Regression Accuracy: {accuracy_logistic}')\n",
    "print(f'Logistic Regression AUC: {auc_logistic}')\n",
    "\n",
    "# 训练线性回归模型\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# 进行预测\n",
    "y_pred_prob_linear = linear_model.predict(X_test)\n",
    "\n",
    "# 将预测的连续值转换为二分类结果\n",
    "y_pred_linear = (y_pred_prob_linear >= 0.5).astype(int)\n",
    "\n",
    "# 计算线性回归的准确率和AUC\n",
    "accuracy_linear = accuracy_score(y_test, y_pred_linear)\n",
    "auc_linear = roc_auc_score(y_test, y_pred_prob_linear)\n",
    "print(f'Linear Regression Accuracy: {accuracy_linear}')\n",
    "print(f'Linear Regression AUC: {auc_linear}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecd630-46ef-49c5-ab5d-8311b37f1ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
