{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69b64e5-8150-4981-90d1-6036d1c5068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3775828/2836267656.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/tmp/ipykernel_3775828/2836267656.py:7: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  edges_df = pd.read_csv('GNN/protein_interactions.csv')\n",
      "/tmp/ipykernel_3775828/2836267656.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edges_df['combined_score'][7] = 594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14450\n",
      "18838\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "edges_df = pd.read_csv('GNN/protein_interactions.csv')\n",
    "\n",
    "col_name = ['protein']\n",
    "for i in range(1,769):\n",
    "  col_name.append('feature'+str(i))\n",
    "features_df = pd.read_csv('GNN/gene_embedding_GeneLLM_2.csv', header=None, names=col_name)\n",
    "labels_df = pd.read_csv('GNN/solubility.csv')\n",
    "edges_df['combined_score'][7] = 594\n",
    "edges_df_cleaned = edges_df.dropna()\n",
    "node_id_f = [node_id for node_id in features_df['protein']]\n",
    "node_id_e1 = [node_id for node_id in edges_df_cleaned['protein1']]\n",
    "node_id_e2 = [node_id for node_id in edges_df_cleaned['protein2']]\n",
    "node_id_e = list(set(node_id_e1 + node_id_e2))\n",
    "print(len(node_id_f))\n",
    "print(len(node_id_e))\n",
    "labels_df.rename(columns={'Gene name': 'protein'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b099adb-0d6e-46a1-88ab-2c7e6c5e32a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodes_in_features = set(features_df['protein'])\n",
    "\n",
    "filtered_edges_df = edges_df[\n",
    "    edges_df['protein1'].isin(nodes_in_features) & edges_df['protein2'].isin(nodes_in_features)\n",
    "]\n",
    "# 过滤特征数据集，保留共同节点的特征\n",
    "filtered_features_df = features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3403c5eb-abba-40be-9316-9644b0c5071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High Count' 'Low Count']\n",
      "       protein Solubility  Label  Word_Count  Count_Category\n",
      "0        ERAP2   Membrane      0         117               0\n",
      "1     ADAMTSL5    Soluble      1          28               1\n",
      "2      TBC1D30   Membrane      0          55               0\n",
      "3       KCNK18   Membrane      0         184               0\n",
      "4         NDNF    Soluble      1         129               0\n",
      "...        ...        ...    ...         ...             ...\n",
      "1374   TRABD2B   Membrane      0          96               0\n",
      "1375      RPS9    Soluble      1         205               0\n",
      "1376  SLC22A16   Membrane      0          93               0\n",
      "1377      FBN3    Soluble      1          90               0\n",
      "1378      BDH2    Soluble      1         102               0\n",
      "\n",
      "[1379 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# 将第二列中的两种字符映射为0和1\n",
    "unique_values = labels_df['Count_Category'].unique()\n",
    "print(unique_values)\n",
    "mapping = {unique_values[0]: 0, unique_values[1]: 1}\n",
    "\n",
    "labels_df['Count_Category'] = labels_df['Count_Category'].map(mapping)\n",
    "# 显示更新后的DataFrame\n",
    "print(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38a0d87-fa7b-4488-9849-66843db4f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3775828/744925070.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_edges_df['combined_score'] = pd.to_numeric(filtered_edges_df['combined_score'], errors='coerce', downcast='float')\n"
     ]
    }
   ],
   "source": [
    "node_id_to_index = {node_id: i for i, node_id in enumerate(filtered_features_df['protein'])}\n",
    "# 确保edge_index是按照这个新的索引顺序排列的\n",
    "source_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['protein1']]\n",
    "target_indices = [node_id_to_index[node_id] for node_id in filtered_edges_df['protein2']]\n",
    "edge_index = torch.tensor([source_indices, target_indices], dtype=torch.long)\n",
    "filtered_edges_df['combined_score'] = pd.to_numeric(filtered_edges_df['combined_score'], errors='coerce', downcast='float')\n",
    "edge_weight = torch.tensor(filtered_edges_df['combined_score'].values, dtype=torch.float)\n",
    "\n",
    "# 重排特征矩阵以匹配edge_index的顺序\n",
    "features = filtered_features_df.iloc[:, 1:].values\n",
    "#features = features[[node_id_to_index[node_id] for node_id in filtered_features_df['protein']], :]\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "features_tensor = torch.tensor(features, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae7ab74-a878-4a4e-a6fa-b2d4fbf09035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379\n",
      "1379\n",
      "14450\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_df))\n",
    "nodes_in_labels = set(labels_df['protein'])\n",
    "nodes_in_filter_features = set(filtered_features_df['protein'])\n",
    "common_nodes_labels = nodes_in_labels.intersection(nodes_in_filter_features)\n",
    "\n",
    "# 过滤\n",
    "filtered_labels_df = labels_df[labels_df['protein'].isin(common_nodes_labels)].reset_index(drop=True)\n",
    "print(len(filtered_labels_df))\n",
    "print(len(features_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d35e6171-1a2b-4af3-8253-3242321ec840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3775828/4172329668.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels_tensor = torch.tensor(labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "label_indices = [node_id_to_index[node_id] for node_id in filtered_labels_df['protein']]\n",
    "num_nodes = 14450\n",
    "labels = torch.full((num_nodes,), -1, dtype=torch.long)\n",
    "for i, index in enumerate(filtered_labels_df['Label']):\n",
    "    labels[label_indices[i]] = index\n",
    "\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7212a23-5055-4d8c-9b4c-1679ee4648d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_labels_df.to_csv('GNN/new_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28645546-7292-43ec-aee2-f57fbf093c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>Label</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>Count_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ERAP2</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADAMTSL5</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TBC1D30</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KCNK18</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDNF</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>TRABD2B</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>RPS9</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>SLC22A16</td>\n",
       "      <td>Membrane</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>FBN3</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>BDH2</td>\n",
       "      <td>Soluble</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       protein Solubility  Label  Word_Count  Count_Category\n",
       "0        ERAP2   Membrane      0         117               0\n",
       "1     ADAMTSL5    Soluble      1          28               1\n",
       "2      TBC1D30   Membrane      0          55               0\n",
       "3       KCNK18   Membrane      0         184               0\n",
       "4         NDNF    Soluble      1         129               0\n",
       "...        ...        ...    ...         ...             ...\n",
       "1374   TRABD2B   Membrane      0          96               0\n",
       "1375      RPS9    Soluble      1         205               0\n",
       "1376  SLC22A16   Membrane      0          93               0\n",
       "1377      FBN3    Soluble      1          90               0\n",
       "1378      BDH2    Soluble      1         102               0\n",
       "\n",
       "[1379 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7d99ed0-85cd-484a-8d8f-d84209e4aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "highinfo_indices = [\n",
    "    node_id_to_index[node_id]\n",
    "    for node_id, weight in zip(filtered_labels_df['protein'], filtered_labels_df['Count_Category'])\n",
    "    if weight == 0\n",
    "]\n",
    "lowinfo_indices = [\n",
    "    node_id_to_index[node_id]\n",
    "    for node_id, weight in zip(filtered_labels_df['protein'], filtered_labels_df['Count_Category'])\n",
    "    if weight == 1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb7c35f-96c8-4620-9062-cd9493bc3d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([14450, 768]) torch.float32\n",
      "edge_index: torch.Size([2, 9503503]) torch.int64\n",
      "labels: torch.Size([14450]) torch.int64\n",
      "edge_weight: torch.Size([9503503]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "data = Data(x=features_tensor, edge_index=edge_index, y=labels_tensor, edge_attr=edge_weight)\n",
    "\n",
    "print(\"x:\", data.x.shape, data.x.dtype)\n",
    "print(\"edge_index:\", data.edge_index.shape, data.edge_index.dtype)\n",
    "print(\"labels:\", data.y.shape, data.y.dtype)\n",
    "print(\"edge_weight:\", data.edge_attr.shape, data.edge_attr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9dee22d-3c63-47d4-b150-12e2390b5ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, num_layers, in_dim, num_hidden, num_classes, heads, activation, dropout, negative_slope, residual):\n",
    "        super(GAT, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.gat_layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "\n",
    "        # Input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads=heads[0],\n",
    "            dropout=dropout, negative_slope=negative_slope, concat=True, add_self_loops=True))\n",
    "\n",
    "        # Hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # Due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads=heads[l],\n",
    "                dropout=dropout, negative_slope=negative_slope, concat=True, add_self_loops=True))\n",
    "\n",
    "        # Output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads=heads[-1],\n",
    "            dropout=dropout, negative_slope=negative_slope, concat=False, add_self_loops=True))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = x\n",
    "        for l, layer in enumerate(self.gat_layers[:-1]):\n",
    "            h = layer(h, edge_index)\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            if l < self.num_layers - 1:\n",
    "                h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Output projection\n",
    "        logits = self.gat_layers[-1](h, edge_index)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6667a8c1-98fe-4035-a4a4-ba35bce6fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 128)\n",
    "        self.conv2 = GCNConv(128, hidden_dim)\n",
    "        self.fc1 = torch.nn.Linear(hidden_dim, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, num_classes)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 保存初始特征\n",
    "        initial_features = x\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)   #应用 Sigmoid 激活函数进行逻辑回归\n",
    "        return x\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Linear, ModuleList, Dropout\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim, num_classes, num_layers, activation, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.convs = ModuleList([GCNConv(hidden_dim, hidden_dim) for _ in range(num_layers - 2)])\n",
    "        self.conv_last = GCNConv(hidden_dim, num_classes)\n",
    "        self.activation = activation\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 输入层\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 隐藏层\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # 输出层\n",
    "        x = self.conv_last(x, edge_index)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ed1149-e50d-4a7e-a921-fcdd3e863b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    r\"\"\"Computes the accuracy of correct predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    return (pred == target).sum().item() / target.numel()\n",
    "\n",
    "\n",
    "\n",
    "def true_positive(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of true positive predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred == i) & (target == i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def true_negative(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of true negative predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred != i) & (target != i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def false_positive(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of false positive predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred == i) & (target != i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def false_negative(pred, target, num_classes):\n",
    "    r\"\"\"Computes the number of false negative predictions.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`LongTensor`\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for i in range(num_classes):\n",
    "        out.append(((pred != i) & (target == i)).sum())\n",
    "\n",
    "    return torch.tensor(out)\n",
    "\n",
    "\n",
    "\n",
    "def precision(pred, target, num_classes):\n",
    "    r\"\"\"Computes the precision:\n",
    "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
    "    fp = false_positive(pred, target, num_classes).to(torch.float)\n",
    "\n",
    "    out = tp / (tp + fp)\n",
    "    out[torch.isnan(out)] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def recall(pred, target, num_classes):\n",
    "    r\"\"\"Computes the recall:\n",
    "    :math:`\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    tp = true_positive(pred, target, num_classes).to(torch.float)\n",
    "    fn = false_negative(pred, target, num_classes).to(torch.float)\n",
    "\n",
    "    out = tp / (tp + fn)\n",
    "    out[torch.isnan(out)] = 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def f1_score(pred, target, num_classes):\n",
    "    r\"\"\"Computes the :math:`F_1` score:\n",
    "    :math:`2 \\cdot \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}\n",
    "    {\\mathrm{precision}+\\mathrm{recall}}`.\n",
    "\n",
    "    Args:\n",
    "        pred (Tensor): The predictions.\n",
    "        target (Tensor): The targets.\n",
    "        num_classes (int): The number of classes.\n",
    "\n",
    "    :rtype: :class:`Tensor`\n",
    "    \"\"\"\n",
    "    prec = precision(pred, target, num_classes)\n",
    "    rec = recall(pred, target, num_classes)\n",
    "\n",
    "    score = 2 * (prec * rec) / (prec + rec)\n",
    "    score[torch.isnan(score)] = 0\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b20aa4b-798d-412d-a43e-f73e36b4fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "def train_model_scheduler(model, masked_features, labels, edge_index, optimizer, criterion, scheduler, train_mask):\n",
    "    model.train()  # 设置模型为训练模\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index)  # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    scheduler.step(loss)\n",
    "    return loss.item()\n",
    "\n",
    "def train_model(model, masked_features, labels, edge_index, optimizer, criterion, train_mask):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "    out = model(masked_features, edge_index) # 获取模型输出\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])  # 计算损失值，只针对训练集的节点\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新模型参数\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate_model(model, features, labels, edge_index, mask):\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    with torch.no_grad():  # 关闭梯度计算\n",
    "        # 获取模型输出，这里假设输出已经是经过sigmoid的概率\n",
    "        probabilities = model(features, edge_index)\n",
    "        if probabilities.shape[1] == 2:  # 假设有两个输出（每个类一个概率）\n",
    "            positive_probs = probabilities[mask, 1]  # 选择正类概率\n",
    "        else:\n",
    "            positive_probs = probabilities[mask]  # 如果只有一个输出，假设已经是正类概率\n",
    "        val_f1 = torch.mean(f1_score(torch.argmax(probabilities[mask],dim=1), labels[mask], num_classes=2)).cpu().numpy()\n",
    "        auc_score = roc_auc_score(labels[mask].cpu().numpy(), positive_probs.cpu().numpy())\n",
    "\n",
    "    return val_f1, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1cff0c9-bc4b-47e6-a4a4-9b3a15bd0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   67,    81,    93,  ..., 14398, 14407, 14426])\n",
      "276\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "Epoch 99: Train Loss:0.6419, Macro_F1: 0.6143, AUC_score: 0.6718\n",
      "Epoch 199: Train Loss:0.6157, Macro_F1: 0.6577, AUC_score: 0.6993\n",
      "Epoch 299: Train Loss:0.6156, Macro_F1: 0.6393, AUC_score: 0.7225\n",
      "Epoch 399: Train Loss:0.5911, Macro_F1: 0.6662, AUC_score: 0.7484\n",
      "Epoch 499: Train Loss:0.5711, Macro_F1: 0.6975, AUC_score: 0.7679\n",
      "Epoch 599: Train Loss:0.5778, Macro_F1: 0.6953, AUC_score: 0.7749\n",
      "Epoch 699: Train Loss:0.5780, Macro_F1: 0.6843, AUC_score: 0.7893\n",
      "Epoch 799: Train Loss:0.5477, Macro_F1: 0.7321, AUC_score: 0.8005\n",
      "Epoch 899: Train Loss:0.5434, Macro_F1: 0.7267, AUC_score: 0.8047\n",
      "Epoch 999: Train Loss:0.5893, Macro_F1: 0.6885, AUC_score: 0.8025\n",
      "Epoch 1099: Train Loss:0.5423, Macro_F1: 0.7232, AUC_score: 0.8281\n",
      "Epoch 1199: Train Loss:0.5513, Macro_F1: 0.7423, AUC_score: 0.8339\n",
      "Epoch 1299: Train Loss:0.5344, Macro_F1: 0.7425, AUC_score: 0.8334\n",
      "Epoch 1399: Train Loss:0.5225, Macro_F1: 0.7704, AUC_score: 0.8352\n",
      "Epoch 1499: Train Loss:0.5216, Macro_F1: 0.7225, AUC_score: 0.8510\n",
      "Epoch 1599: Train Loss:0.5088, Macro_F1: 0.7528, AUC_score: 0.8500\n",
      "Epoch 01674: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 1699: Train Loss:0.5063, Macro_F1: 0.7640, AUC_score: 0.8458\n",
      "Epoch 1799: Train Loss:0.5063, Macro_F1: 0.7549, AUC_score: 0.8441\n",
      "Epoch 1899: Train Loss:0.4998, Macro_F1: 0.7604, AUC_score: 0.8481\n",
      "Epoch 01968: reducing learning rate of group 0 to 2.0000e-04.\n",
      "Epoch 1999: Train Loss:0.5022, Macro_F1: 0.7587, AUC_score: 0.8459\n",
      "Epoch 2099: Train Loss:0.5040, Macro_F1: 0.7590, AUC_score: 0.8463\n",
      "Epoch 02154: reducing learning rate of group 0 to 4.0000e-05.\n",
      "Epoch 2199: Train Loss:0.5028, Macro_F1: 0.7593, AUC_score: 0.8474\n",
      "Epoch 02255: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Epoch 2299: Train Loss:0.5015, Macro_F1: 0.7590, AUC_score: 0.8468\n",
      "Epoch 02390: reducing learning rate of group 0 to 1.6000e-06.\n",
      "Epoch 2399: Train Loss:0.4996, Macro_F1: 0.7628, AUC_score: 0.8469\n",
      "Epoch 02491: reducing learning rate of group 0 to 3.2000e-07.\n",
      "Epoch 2499: Train Loss:0.5028, Macro_F1: 0.7628, AUC_score: 0.8470\n",
      "Epoch 02592: reducing learning rate of group 0 to 6.4000e-08.\n",
      "Epoch 2599: Train Loss:0.5051, Macro_F1: 0.7628, AUC_score: 0.8470\n",
      "Epoch 02693: reducing learning rate of group 0 to 1.2800e-08.\n",
      "Epoch 2699: Train Loss:0.5006, Macro_F1: 0.7628, AUC_score: 0.8470\n",
      "Epoch 02794: reducing learning rate of group 0 to 2.5600e-09.\n",
      "Epoch 2799: Train Loss:0.5064, Macro_F1: 0.7628, AUC_score: 0.8470\n",
      "Epoch 2899: Train Loss:0.5064, Macro_F1: 0.7628, AUC_score: 0.8470\n",
      "Epoch 2999: Train Loss:0.5037, Macro_F1: 0.7628, AUC_score: 0.8470\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "# 实例化模型\n",
    "device = torch.device('cuda:1')\n",
    "data = data.to(device)\n",
    "model = GCN(num_features=features.shape[1], hidden_dim=64, num_classes=2, num_layers=1, activation=F.relu, dropout=0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=100, verbose=True)\n",
    "\n",
    "label_indices = torch.tensor(label_indices, dtype=torch.long)\n",
    "print(label_indices)\n",
    "# 随机打乱有标签的节点索引\n",
    "labeled_indices = label_indices[torch.randperm(label_indices.size(0))]\n",
    "#print(labeled_indices)\n",
    "labeled_indices = label_indices\n",
    "\n",
    "# 定义训练和测试集的大小\n",
    "num_labeled = labeled_indices.size(0)\n",
    "num_train = int(num_labeled * 0.8)\n",
    "num_test = num_labeled - num_train\n",
    "print(num_test)\n",
    "\n",
    "# 创建训练和测试掩码\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[labeled_indices[:num_train]] = True\n",
    "test_mask[labeled_indices[num_train:num_train+num_test]] = True\n",
    "print(test_mask)\n",
    "num_epochs = 3000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model_scheduler(model, data.x, data.y, data.edge_index, optimizer, loss_fn, scheduler, train_mask)\n",
    "    test_f1, test_auc = evaluate_model(model, data.x, data.y, data.edge_index, test_mask)\n",
    "    \n",
    "    if (epoch+1) % 100 == 0: \n",
    "        print(f'Epoch {epoch}: Train Loss:{train_loss:.4f}, Macro_F1: {test_f1:.4f}, AUC_score: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e2afd54-260e-4d73-8590-e7642438d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers=1\n",
    "n_heads = 4\n",
    "heads = ([n_heads] * num_layers) + [1]\n",
    "heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a046f52-069f-4d7f-9125-13c98d22aff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   67,    81,    93,  ..., 14398, 14407, 14426])\n",
      "276\n",
      "tensor([False, False, False,  ..., False, False, False])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3775828/3626462267.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_indices = torch.tensor(label_indices, dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss: 0.6736, Macro_F1: 0.5624, AUC_score: 0.6681\n",
      "Epoch 99: Train Loss: 0.6420, Macro_F1: 0.6173, AUC_score: 0.6781\n",
      "Epoch 149: Train Loss: 0.5824, Macro_F1: 0.6718, AUC_score: 0.7556\n",
      "Epoch 199: Train Loss: 0.5505, Macro_F1: 0.5969, AUC_score: 0.7927\n",
      "Epoch 249: Train Loss: 0.5571, Macro_F1: 0.5955, AUC_score: 0.8173\n",
      "Epoch 299: Train Loss: 0.4780, Macro_F1: 0.7533, AUC_score: 0.8389\n",
      "Epoch 349: Train Loss: 0.4594, Macro_F1: 0.8090, AUC_score: 0.8536\n",
      "Epoch 399: Train Loss: 0.4841, Macro_F1: 0.7825, AUC_score: 0.8562\n",
      "Epoch 449: Train Loss: 0.4332, Macro_F1: 0.8076, AUC_score: 0.8626\n",
      "Epoch 499: Train Loss: 0.4207, Macro_F1: 0.7824, AUC_score: 0.8631\n",
      "Epoch 549: Train Loss: 0.4246, Macro_F1: 0.8029, AUC_score: 0.8649\n",
      "Epoch 599: Train Loss: 0.4019, Macro_F1: 0.7861, AUC_score: 0.8691\n",
      "Epoch 649: Train Loss: 0.3975, Macro_F1: 0.7862, AUC_score: 0.8676\n",
      "Epoch 699: Train Loss: 0.3990, Macro_F1: 0.8110, AUC_score: 0.8746\n",
      "Epoch 749: Train Loss: 0.3859, Macro_F1: 0.7934, AUC_score: 0.8722\n",
      "Epoch 799: Train Loss: 0.3826, Macro_F1: 0.7717, AUC_score: 0.8718\n",
      "Epoch 849: Train Loss: 0.3930, Macro_F1: 0.8145, AUC_score: 0.8748\n",
      "Epoch 899: Train Loss: 0.3735, Macro_F1: 0.8113, AUC_score: 0.8724\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "device = torch.device('cuda:1')\n",
    "data = data.to(device)\n",
    "\n",
    "model = GAT(num_layers=1, \n",
    "            in_dim=features.shape[1], \n",
    "            num_hidden=64, \n",
    "            num_classes=2, \n",
    "            heads = heads, \n",
    "            activation=F.elu, dropout=0.6, negative_slope=0.2, residual=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=200, verbose=True)\n",
    "\n",
    "label_indices = torch.tensor(label_indices, dtype=torch.long)\n",
    "print(label_indices)\n",
    "# 随机打乱有标签的节点索引\n",
    "labeled_indices = label_indices[torch.randperm(label_indices.size(0))]\n",
    "#print(labeled_indices)\n",
    "labeled_indices = label_indices\n",
    "\n",
    "# 定义训练和测试集的大小\n",
    "num_labeled = labeled_indices.size(0)\n",
    "num_train = int(num_labeled * 0.8)\n",
    "num_test = num_labeled - num_train\n",
    "print(num_test)\n",
    "\n",
    "# 创建训练和测试掩码\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[labeled_indices[:num_train]] = True\n",
    "test_mask[labeled_indices[num_train:num_train+num_test]] = True\n",
    "print(test_mask)\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model_scheduler(model, data.x, data.y, data.edge_index, optimizer, loss_fn, scheduler, train_mask)\n",
    "    #train_loss = train_model(model, data.x, data.y, data.edge_index, optimizer, loss_fn, train_mask)\n",
    "    test_acc, test_auc = evaluate_model(model, data.x, data.y, data.edge_index, test_mask)\n",
    "    \n",
    "    if (epoch+1) % 50 == 0: \n",
    "        print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, Macro_F1: {test_acc:.4f}, AUC_score: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f8faaa-94ae-4599-b379-2cdd952d266e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
